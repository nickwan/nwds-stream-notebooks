{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nickwan/nwds-stream-notebooks/blob/main/24_nwvs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4muvMNnVE2ME"
      },
      "source": [
        "# font size stuff (doesn't help with nwvs, just notebook output text size for stream)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b08_WqHaFHq6"
      },
      "outputs": [],
      "source": [
        "def increase_font():\n",
        "  from IPython.display import Javascript\n",
        "  display(Javascript('''\n",
        "  for (rule of document.styleSheets[0].cssRules){\n",
        "    if (rule.selectorText=='body') {\n",
        "      rule.style.fontSize = '24px'\n",
        "      break\n",
        "    }\n",
        "  }\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', increase_font)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z0e4pcCJVOi"
      },
      "source": [
        "RULES\n",
        "# What is nwvs?\n",
        "Also known as Nick Wan Versus  \n",
        "I challenge all competitive data scientists to a 2-hour data science modeling prediction competition on Kaggle. Everyone (including me) will not know what the dataset is until 9pm ET. From 9pm ET to 11pm ET, we have to develop a model and submit model predictions to a Kaggle competition page (which will be revealed at 9pm ET).  \n",
        "\n",
        "Last year's nwvs can be found here:  \n",
        "https://www.kaggle.com/competitions/portland-housing-age-prediction-nwvs-s00e01  \n",
        "\n",
        "Everyone who beats me on the leaderboard and posts their notebook on Kaggle can receive a free gifted sub from me. For those who beat me and don't provide a notebook of their work, I will anonymously gift the chat the sub. For example: if I place 6th, I owe 6 subs. If the top 3 people don't post their notebooks on Kaggle, I will gift 3 of the 6 subs to chat randomly.  \n",
        "\n",
        "NWVS starts at 9pm ET on Tuesday, 1/16.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZne50sfJcnT"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDoWu0EZFHuL"
      },
      "source": [
        "# MY CODE dejj\n",
        "\n",
        "to do list:  \n",
        "~~start big timer first  \n",
        "get link  \n",
        "nightbot update  \n",
        "tweet  \n",
        "download data  \n",
        "set the path  \n",
        "speed run (pred)  \n",
        "execute rest of plan  ~~\n",
        "4 legit entries before the end of the first hour (pred? ask chat)   \n",
        "place 1st on public board one time in the first 15 mins of the 2nd hour (pred)   \n",
        "start gamba for top 5 with 15 mins left, maybe 10 left (pred)  \n",
        "\n",
        "my plan:  \n",
        "1. regular pipeline\n",
        "2. lightgbm deny?  \n",
        "3. tune xgb  \n",
        "4. tune cb  \n",
        "5a. if denied, swap for h2o small  \n",
        "5b. if accepted, tune lgbm  \n",
        "6. h2o big  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AGjj3209KiVm",
        "outputId": "693dc8ba-9403-47f0-c76d-d065cd08375e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '24px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.5.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.24)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.4)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.0 alembic-1.13.1 colorlog-6.8.0 optuna-3.5.0\n",
            "Collecting h2o\n",
            "  Downloading h2o-3.44.0.3.tar.gz (265.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.2/265.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from h2o) (2.31.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from h2o) (0.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2023.11.17)\n",
            "Building wheels for collected packages: h2o\n",
            "  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for h2o: filename=h2o-3.44.0.3-py2.py3-none-any.whl size=265293968 sha256=3f32f19100c3f26087d9f962a3a1b9663aa97654c6411ab6323b374b781443fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/9a/1c/2da26f943fd46b57f3c20b54847b936b9152b831dc7447cf71\n",
            "Successfully built h2o\n",
            "Installing collected packages: h2o\n",
            "Successfully installed h2o-3.44.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "!pip install optuna\n",
        "!pip install h2o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "oF0QEDg0Ke11",
        "outputId": "363c5540-0308-4211-b8dd-cb1333682970"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '24px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
            "Attempting to start a local H2O server...\n",
            "  Java Version: openjdk version \"11.0.21\" 2023-10-17; OpenJDK Runtime Environment (build 11.0.21+9-post-Ubuntu-0ubuntu122.04); OpenJDK 64-Bit Server VM (build 11.0.21+9-post-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n",
            "  Starting server from /usr/local/lib/python3.10/dist-packages/h2o/backend/bin/h2o.jar\n",
            "  Ice root: /tmp/tmpkh21fetn\n",
            "  JVM stdout: /tmp/tmpkh21fetn/h2o_unknownUser_started_from_python.out\n",
            "  JVM stderr: /tmp/tmpkh21fetn/h2o_unknownUser_started_from_python.err\n",
            "  Server is running at http://127.0.0.1:54321\n",
            "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------  -----------------------------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         07 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.44.0.3\n",
              "H2O_cluster_version_age:    1 month and 5 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_1vt6oe\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    3.170 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://127.0.0.1:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.10.12 final\n",
              "--------------------------  -----------------------------------------------------------------------------------------"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-1.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-1 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-1 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-1 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table th,\n",
              "#h2o-table-1 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption></caption>\n",
              "    <thead></thead>\n",
              "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>07 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.44.0.3</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>1 month and 5 days</td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_1vt6oe</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>3.170 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://127.0.0.1:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.10.12 final</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import optuna as opt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import catboost as cb\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold, GroupKFold\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import h2o\n",
        "h2o.init()\n",
        "\n",
        "from h2o.estimators.deeplearning import H2ODeepLearningEstimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "f-sOUw05KFLb",
        "outputId": "06d68f0f-42ce-4041-921f-7438352d7b99"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '24px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "train['test'] = 0\n",
        "test['test'] = 1\n",
        "data = pd.concat([train, test], ignore_index=True)\n",
        "cols = [\n",
        "    'race', 'date', 'time', 'circuit', 'driver', 'constructor'\n",
        "]\n",
        "\n",
        "for col in cols:\n",
        "  data[f'{col}_code'] = data[col].astype('category').cat.codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "CvcAszffKFQG",
        "outputId": "9d665bd9-cc91-4894-a82b-f340e9870a35"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '24px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'latitude', 'longitude', 'altitude', 'carNumber',\n",
              "       'avgDriverFinish', 'avgConstructorFinish', 'lapNumber', 'lapPosition',\n",
              "       'pitStop', 'pitCount', 'pitTime_ms', 'lapTime_ms', 'test', 'race_code',\n",
              "       'date_code', 'time_code', 'circuit_code', 'driver_code',\n",
              "       'constructor_code'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "x = data.dtypes\n",
        "x[x!='object'].index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sd_not_lead_lap.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "r8-_dygEighc",
        "outputId": "dee67efe-d844-414a-f980-73a99db38404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '24px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'sd_not_lead_lap' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d052a4a16ffb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msd_not_lead_lap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sd_not_lead_lap' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYhTdQpARHde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "outputId": "9c727435-2399-44f0-eda1-4ac16967ce2b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '24px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50714, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "avg_lead_lap = data.loc[data['lapPosition']<=5, ['driver','lapTime_ms']].groupby(['driver'], as_index=False).mean()\n",
        "sd_lead_lap = data.loc[data['lapPosition']<=5, ['driver','lapTime_ms']].groupby(['driver'], as_index=False).std()\n",
        "avg_pit = data.loc[:, ['constructor','pitTime_ms']].groupby(['constructor'], as_index=False).mean()\n",
        "sd_pit = data.loc[:, ['constructor','pitTime_ms']].groupby(['constructor'], as_index=False).std()\n",
        "\n",
        "avg_track_lap = data.loc[data['lapPosition']<=10, ['circuit_code', 'lapNumber','lapTime_ms']].groupby(['circuit_code', 'lapNumber'], as_index=False).mean()\n",
        "sd_track_lap = data.loc[data['lapPosition']<=10, ['circuit_code', 'lapNumber','lapTime_ms']].groupby(['circuit_code', 'lapNumber'], as_index=False).std()\n",
        "\n",
        "avg_not_lead_lap = data.loc[data['lapPosition'].between(5,10), ['driver','lapTime_ms']].groupby(['driver'], as_index=False).mean()\n",
        "sd_not_lead_lap = data.loc[data['lapPosition'].between(5,10), ['driver','lapTime_ms']].groupby(['driver'], as_index=False).std()\n",
        "\n",
        "data = data.merge(avg_track_lap.rename(columns={'lapTime_ms':'avgTrackLap'}), how='left').fillna(-1)\n",
        "data = data.merge(sd_track_lap.rename(columns={'lapTime_ms':'sdTrackLap'}), how='left').fillna(-1)\n",
        "data = data.merge(avg_lead_lap.rename(columns={'pitTime_ms':'avgLeadLap'}), how='left').fillna(-1)\n",
        "data = data.merge(sd_lead_lap.rename(columns={'pitTime_ms':'sdLeadLap'}), how='left').fillna(-1)\n",
        "data = data.merge(avg_pit.rename(columns={'pitTime_ms':'avgPitTime'}), how='left').fillna(-1)\n",
        "data = data.merge(sd_pit.rename(columns={'pitTime_ms':'sdPitTime'}), how='left').fillna(-1)\n",
        "\n",
        "data = data.merge(avg_not_lead_lap.rename(columns={'lapTime_ms':'avgNotLeadLap'}), how='left').fillna(-1)\n",
        "data = data.merge(sd_not_lead_lap.rename(columns={'lapTime_ms':'sdNotLeadLap'}), how='left').fillna(-1)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "gmNSQYNuiWbc",
        "outputId": "22182be9-77e2-407e-8ed8-c47116e7ff2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '24px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['id', 'race', 'date', 'time', 'circuit', 'latitude', 'longitude',\n",
              "       'altitude', 'driver', 'carNumber', 'constructor',\n",
              "       'avgDriverFinish', 'avgConstructorFinish', 'lapNumber',\n",
              "       'lapPosition', 'pitStop', 'pitCount', 'pitTime_ms', 'lapTime_ms',\n",
              "       'test', 'race_code', 'date_code', 'time_code', 'circuit_code',\n",
              "       'driver_code', 'constructor_code', 'avgTrackLap', 'sdTrackLap',\n",
              "       'avgPitTime', 'sdPitTime', 'avgNotLeadLap', 'sdNotLeadLap'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[(data['race']=='British Grand Prix') & (data['driver']=='Ricciardo, Daniel'), ['id','date','driver','lapNumber','pitCount', 'lapTime_ms']].sort_values(['date','lapNumber']).head(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MRIaO5dKn1B7",
        "outputId": "93189d8e-88c2-4f62-d40e-2507e9305248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '24px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id        date             driver  lapNumber  pitCount  lapTime_ms\n",
              "47524  47525  2015-07-05  Ricciardo, Daniel          1         0        -1.0\n",
              "48536  48537  2015-07-05  Ricciardo, Daniel          2         0        -1.0\n",
              "9452    9453  2015-07-05  Ricciardo, Daniel          3         0    140362.0\n",
              "49425  49426  2015-07-05  Ricciardo, Daniel          4         0        -1.0\n",
              "13305  13306  2015-07-05  Ricciardo, Daniel          5         0    102341.0\n",
              "49554  49555  2015-07-05  Ricciardo, Daniel          6         0        -1.0\n",
              "44419  44420  2015-07-05  Ricciardo, Daniel          7         0        -1.0\n",
              "17421  17422  2015-07-05  Ricciardo, Daniel          8         0    100499.0\n",
              "14224  14225  2015-07-05  Ricciardo, Daniel          9         0    101008.0\n",
              "31468  31469  2015-07-05  Ricciardo, Daniel         10         0        -1.0\n",
              "4248    4249  2015-07-05  Ricciardo, Daniel         11         1     99119.0\n",
              "17617  17618  2015-07-05  Ricciardo, Daniel         12         1    119861.0\n",
              "12722  12723  2015-07-05  Ricciardo, Daniel         13         1    100463.0\n",
              "13453  13454  2015-07-05  Ricciardo, Daniel         14         1     99940.0\n",
              "42662  42663  2015-07-05  Ricciardo, Daniel         15         1        -1.0\n",
              "15182  15183  2015-07-05  Ricciardo, Daniel         16         1    104488.0\n",
              "42008  42009  2015-07-05  Ricciardo, Daniel         17         1        -1.0\n",
              "26812  26813  2015-07-05  Ricciardo, Daniel         18         1    105090.0\n",
              "30150  30151  2015-07-05  Ricciardo, Daniel         19         1        -1.0\n",
              "40902  40903  2015-07-05  Ricciardo, Daniel         20         2        -1.0\n",
              "17643  17644  2015-07-05  Ricciardo, Daniel         21         2    141451.0\n",
              "21098  21099  2017-07-16  Ricciardo, Daniel          1         0    107461.0\n",
              "41586  41587  2017-07-16  Ricciardo, Daniel          2         0        -1.0\n",
              "47451  47452  2017-07-16  Ricciardo, Daniel          3         0        -1.0\n",
              "8427    8428  2017-07-16  Ricciardo, Daniel          4         0    137797.0\n",
              "30698  30699  2017-07-16  Ricciardo, Daniel          5         0        -1.0\n",
              "24544  24545  2017-07-16  Ricciardo, Daniel          6         0     97150.0\n",
              "2123    2124  2017-07-16  Ricciardo, Daniel          7         0     95356.0\n",
              "43121  43122  2017-07-16  Ricciardo, Daniel          8         0        -1.0\n",
              "42015  42016  2017-07-16  Ricciardo, Daniel          9         0        -1.0\n",
              "42075  42076  2017-07-16  Ricciardo, Daniel         10         0        -1.0\n",
              "28281  28282  2017-07-16  Ricciardo, Daniel         11         0     95797.0\n",
              "44852  44853  2017-07-16  Ricciardo, Daniel         12         0        -1.0\n",
              "43528  43529  2017-07-16  Ricciardo, Daniel         13         0        -1.0\n",
              "46105  46106  2017-07-16  Ricciardo, Daniel         14         0        -1.0\n",
              "540      541  2017-07-16  Ricciardo, Daniel         15         0     94795.0\n",
              "9536    9537  2017-07-16  Ricciardo, Daniel         16         0     94466.0\n",
              "12691  12692  2017-07-16  Ricciardo, Daniel         17         0     94621.0\n",
              "0          1  2017-07-16  Ricciardo, Daniel         18         0     94846.0\n",
              "3886    3887  2017-07-16  Ricciardo, Daniel         19         0     94658.0\n",
              "47774  47775  2017-07-16  Ricciardo, Daniel         20         0        -1.0\n",
              "16847  16848  2017-07-16  Ricciardo, Daniel         21         0     94459.0\n",
              "42155  42156  2017-07-16  Ricciardo, Daniel         22         0        -1.0\n",
              "12151  12152  2017-07-16  Ricciardo, Daniel         23         0     94332.0\n",
              "26794  26795  2017-07-16  Ricciardo, Daniel         24         0     93990.0\n",
              "16545  16546  2017-07-16  Ricciardo, Daniel         25         0     93836.0\n",
              "24264  24265  2017-07-16  Ricciardo, Daniel         26         0     93838.0\n",
              "29875  29876  2017-07-16  Ricciardo, Daniel         27         0     94147.0\n",
              "7676    7677  2017-07-16  Ricciardo, Daniel         28         0     93856.0\n",
              "22655  22656  2017-07-16  Ricciardo, Daniel         29         0     94043.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f92ca81-a887-4f05-b091-cb8a2fae57e5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>driver</th>\n",
              "      <th>lapNumber</th>\n",
              "      <th>pitCount</th>\n",
              "      <th>lapTime_ms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>47524</th>\n",
              "      <td>47525</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48536</th>\n",
              "      <td>48537</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9452</th>\n",
              "      <td>9453</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>140362.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49425</th>\n",
              "      <td>49426</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13305</th>\n",
              "      <td>13306</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>102341.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49554</th>\n",
              "      <td>49555</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44419</th>\n",
              "      <td>44420</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17421</th>\n",
              "      <td>17422</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>100499.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14224</th>\n",
              "      <td>14225</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>101008.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31468</th>\n",
              "      <td>31469</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4248</th>\n",
              "      <td>4249</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>99119.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17617</th>\n",
              "      <td>17618</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>119861.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12722</th>\n",
              "      <td>12723</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>100463.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13453</th>\n",
              "      <td>13454</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>99940.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42662</th>\n",
              "      <td>42663</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15182</th>\n",
              "      <td>15183</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>104488.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42008</th>\n",
              "      <td>42009</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26812</th>\n",
              "      <td>26813</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>105090.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30150</th>\n",
              "      <td>30151</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40902</th>\n",
              "      <td>40903</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17643</th>\n",
              "      <td>17644</td>\n",
              "      <td>2015-07-05</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>141451.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21098</th>\n",
              "      <td>21099</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>107461.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41586</th>\n",
              "      <td>41587</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47451</th>\n",
              "      <td>47452</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8427</th>\n",
              "      <td>8428</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>137797.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30698</th>\n",
              "      <td>30699</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24544</th>\n",
              "      <td>24545</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>97150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2123</th>\n",
              "      <td>2124</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>95356.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43121</th>\n",
              "      <td>43122</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42015</th>\n",
              "      <td>42016</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42075</th>\n",
              "      <td>42076</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28281</th>\n",
              "      <td>28282</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>95797.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44852</th>\n",
              "      <td>44853</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43528</th>\n",
              "      <td>43529</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46105</th>\n",
              "      <td>46106</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>541</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>94795.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9536</th>\n",
              "      <td>9537</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>94466.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12691</th>\n",
              "      <td>12692</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>94621.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>94846.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3886</th>\n",
              "      <td>3887</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>94658.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47774</th>\n",
              "      <td>47775</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16847</th>\n",
              "      <td>16848</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>94459.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42155</th>\n",
              "      <td>42156</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12151</th>\n",
              "      <td>12152</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>94332.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26794</th>\n",
              "      <td>26795</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>93990.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16545</th>\n",
              "      <td>16546</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>93836.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24264</th>\n",
              "      <td>24265</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>93838.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29875</th>\n",
              "      <td>29876</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>94147.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7676</th>\n",
              "      <td>7677</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>93856.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22655</th>\n",
              "      <td>22656</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>Ricciardo, Daniel</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>94043.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f92ca81-a887-4f05-b091-cb8a2fae57e5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3f92ca81-a887-4f05-b091-cb8a2fae57e5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3f92ca81-a887-4f05-b091-cb8a2fae57e5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c51ba89d-4d7e-4099-b7ee-fd8c2db40c63\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c51ba89d-4d7e-4099-b7ee-fd8c2db40c63')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c51ba89d-4d7e-4099-b7ee-fd8c2db40c63 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "EQJvgUjnKFV9",
        "outputId": "4ca3e661-8237-4a29-958e-40c3d61471e8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '24px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "cat_cols = [\n",
        "    'time_code', 'circuit_code',\n",
        "       'driver_code', 'constructor_code','pitStop', 'pitCount',\n",
        "\n",
        "]\n",
        "feats = [\n",
        "    'latitude', 'longitude', 'altitude',\n",
        "       'avgDriverFinish', 'avgConstructorFinish', 'lapNumber', 'lapPosition',\n",
        "       'pitStop', 'pitCount', 'pitTime_ms',\n",
        "       'circuit_code', 'driver_code',\n",
        "       'constructor_code', 'avgTrackLap', 'sdTrackLap',\n",
        "       'avgPitTime', 'sdPitTime', 'avgNotLeadLap', 'sdNotLeadLap'\n",
        "]\n",
        "target = 'lapTime_ms'\n",
        "model_data = data.loc[data['test']==0].dropna(subset=feats+[target])\n",
        "model_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "f1taHVX1O1K5",
        "outputId": "c45ad58d-89d6-45d2-9be0-dd83929bbe13"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '24px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def tune(trial):\n",
        "  p = {\n",
        "      'objective':'reg:squarederror',\n",
        "      'num_round':trial.suggest_int('num_round', 100,500),\n",
        "      'eta':trial.suggest_float('eta', 0, 0.3),\n",
        "      'reg_lambda':trial.suggest_float('reg_lambda', 0, 3),\n",
        "      'reg_alpha':trial.suggest_float('reg_alpha', 0, 3),\n",
        "  }\n",
        "  model = xgb.train(p, xtrain)\n",
        "  _s = pd.Series(model.predict(xtest), index=test.index)\n",
        "  loss = mean_squared_error(test[target], _s)\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8ammtCp1PC86",
        "outputId": "27ea091e-82f0-48aa-d103-7f89c23cbb39"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '24px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:31:58,356] A new study created in memory with name: no-name-74ead017-5715-4c6e-beda-c515c02af6b6\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:58] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:58,449] Trial 0 finished with value: 7706563080.359192 and parameters: {'num_round': 296, 'eta': 0.026595807256909087, 'reg_lambda': 1.9327455425798203, 'reg_alpha': 0.8484742117004257}. Best is trial 0 with value: 7706563080.359192.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:58] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:58,501] Trial 1 finished with value: 7274833175.602879 and parameters: {'num_round': 386, 'eta': 0.18423908625287408, 'reg_lambda': 1.7393710908220816, 'reg_alpha': 1.3734050290255087}. Best is trial 1 with value: 7274833175.602879.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:58] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:58,551] Trial 2 finished with value: 7820891357.659182 and parameters: {'num_round': 400, 'eta': 0.00966324352542035, 'reg_lambda': 1.7029253515429672, 'reg_alpha': 1.9369755427997042}. Best is trial 1 with value: 7274833175.602879.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:58] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:58,605] Trial 3 finished with value: 7711555399.318394 and parameters: {'num_round': 300, 'eta': 0.028800395320068436, 'reg_lambda': 0.9758173308651861, 'reg_alpha': 2.868663600439042}. Best is trial 1 with value: 7274833175.602879.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:58] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:58,652] Trial 4 finished with value: 7270459322.92852 and parameters: {'num_round': 189, 'eta': 0.21937614326762242, 'reg_lambda': 2.3849003565598146, 'reg_alpha': 0.1518055608676543}. Best is trial 4 with value: 7270459322.92852.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:58] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:58,704] Trial 5 finished with value: 7240374998.842808 and parameters: {'num_round': 297, 'eta': 0.22979276824084321, 'reg_lambda': 1.0870912360424438, 'reg_alpha': 0.48813724601831476}. Best is trial 5 with value: 7240374998.842808.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:58] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:58,774] Trial 6 finished with value: 7238305276.74001 and parameters: {'num_round': 286, 'eta': 0.24304204950470193, 'reg_lambda': 0.9371855625966469, 'reg_alpha': 0.6300782096583282}. Best is trial 6 with value: 7238305276.74001.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:58] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:58,831] Trial 7 finished with value: 7630507112.510035 and parameters: {'num_round': 184, 'eta': 0.040102969870345326, 'reg_lambda': 2.7067948350205886, 'reg_alpha': 1.5575902600745675}. Best is trial 6 with value: 7238305276.74001.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:58] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:58,888] Trial 8 finished with value: 7596539816.260906 and parameters: {'num_round': 290, 'eta': 0.04698114185704897, 'reg_lambda': 2.8012316728593016, 'reg_alpha': 0.06077647049959323}. Best is trial 6 with value: 7238305276.74001.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:58] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:58,943] Trial 9 finished with value: 7360246152.064265 and parameters: {'num_round': 383, 'eta': 0.1243616596993305, 'reg_lambda': 1.0431425679242279, 'reg_alpha': 1.2964092204647768}. Best is trial 6 with value: 7238305276.74001.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:58] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:59,013] Trial 10 finished with value: 7173049600.978743 and parameters: {'num_round': 500, 'eta': 0.2961955430517359, 'reg_lambda': 0.19844814581302306, 'reg_alpha': 2.3104988719928596}. Best is trial 10 with value: 7173049600.978743.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:59] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:59,084] Trial 11 finished with value: 7174024852.791113 and parameters: {'num_round': 485, 'eta': 0.2972911382094214, 'reg_lambda': 0.05446914377735318, 'reg_alpha': 2.5697584875047803}. Best is trial 10 with value: 7173049600.978743.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:59] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:59,160] Trial 12 finished with value: 7175988189.674971 and parameters: {'num_round': 499, 'eta': 0.29419144185319285, 'reg_lambda': 0.18978746494016188, 'reg_alpha': 2.6157709024171885}. Best is trial 10 with value: 7173049600.978743.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:59] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:59,239] Trial 13 finished with value: 7167420783.489189 and parameters: {'num_round': 491, 'eta': 0.29863606539044374, 'reg_lambda': 0.2632630287919478, 'reg_alpha': 2.2753588887148295}. Best is trial 13 with value: 7167420783.489189.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:59] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:59,312] Trial 14 finished with value: 7391271945.25585 and parameters: {'num_round': 438, 'eta': 0.1106034272875433, 'reg_lambda': 0.5129001048974403, 'reg_alpha': 2.051664109493549}. Best is trial 13 with value: 7167420783.489189.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:59] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:59,387] Trial 15 finished with value: 7214295660.732268 and parameters: {'num_round': 448, 'eta': 0.26690914231448104, 'reg_lambda': 0.5141473366486069, 'reg_alpha': 2.187862807684913}. Best is trial 13 with value: 7167420783.489189.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:59] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:59,471] Trial 16 finished with value: 7264775569.922479 and parameters: {'num_round': 122, 'eta': 0.18076119962020776, 'reg_lambda': 0.4927848439353626, 'reg_alpha': 2.335025421614578}. Best is trial 13 with value: 7167420783.489189.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:59] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:59,537] Trial 17 finished with value: 7174512391.017707 and parameters: {'num_round': 350, 'eta': 0.27425443404070543, 'reg_lambda': 0.2346089109543707, 'reg_alpha': 1.740554852394768}. Best is trial 13 with value: 7167420783.489189.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:59] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:59,607] Trial 18 finished with value: 7271451272.697954 and parameters: {'num_round': 453, 'eta': 0.17874336732523066, 'reg_lambda': 1.2549069592067355, 'reg_alpha': 2.525668027754125}. Best is trial 13 with value: 7167420783.489189.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:59] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:59,677] Trial 19 finished with value: 7220555594.9702 and parameters: {'num_round': 344, 'eta': 0.2578990064649831, 'reg_lambda': 0.7183527669016466, 'reg_alpha': 2.824574332009825}. Best is trial 13 with value: 7167420783.489189.\n",
            "[I 2024-01-26 02:31:59,709] A new study created in memory with name: no-name-74bf2ae7-a8f1-4db1-b8a5-f5c1a9ac3226\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:59] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:59,836] Trial 0 finished with value: 729756195.2818726 and parameters: {'num_round': 136, 'eta': 0.15408297625900777, 'reg_lambda': 0.9361469372264307, 'reg_alpha': 0.5483327042449314}. Best is trial 0 with value: 729756195.2818726.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:59] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:59,899] Trial 1 finished with value: 704086976.566527 and parameters: {'num_round': 125, 'eta': 0.179021560635209, 'reg_lambda': 0.8512755942120672, 'reg_alpha': 1.3123559350061862}. Best is trial 1 with value: 704086976.566527.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:59] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:31:59,959] Trial 2 finished with value: 827980037.1869283 and parameters: {'num_round': 123, 'eta': 0.13233123419238976, 'reg_lambda': 0.20028268008386363, 'reg_alpha': 2.195763450403719}. Best is trial 1 with value: 704086976.566527.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:31:59] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:00,009] Trial 3 finished with value: 666720962.6261543 and parameters: {'num_round': 103, 'eta': 0.17510096373866674, 'reg_lambda': 1.989210273442275, 'reg_alpha': 2.3953038115565337}. Best is trial 3 with value: 666720962.6261543.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:00] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:00,074] Trial 4 finished with value: 723293503.7365078 and parameters: {'num_round': 237, 'eta': 0.19825040753543235, 'reg_lambda': 0.7275900973833948, 'reg_alpha': 0.26574844408253484}. Best is trial 3 with value: 666720962.6261543.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:00] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:00,125] Trial 5 finished with value: 635205378.8839086 and parameters: {'num_round': 127, 'eta': 0.2613753077654836, 'reg_lambda': 2.814962321796189, 'reg_alpha': 1.0321989355792942}. Best is trial 5 with value: 635205378.8839086.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:00] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:00,182] Trial 6 finished with value: 632512246.4482095 and parameters: {'num_round': 138, 'eta': 0.20278050515690266, 'reg_lambda': 2.358502686027462, 'reg_alpha': 2.396694570800448}. Best is trial 6 with value: 632512246.4482095.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:00] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:00,242] Trial 7 finished with value: 855728745.2789711 and parameters: {'num_round': 206, 'eta': 0.11839290105364086, 'reg_lambda': 0.6321025458321764, 'reg_alpha': 2.740070162141822}. Best is trial 6 with value: 632512246.4482095.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:00] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:00,301] Trial 8 finished with value: 896960829.5650316 and parameters: {'num_round': 279, 'eta': 0.11511831905580464, 'reg_lambda': 1.5573373549927987, 'reg_alpha': 0.15511498317667827}. Best is trial 6 with value: 632512246.4482095.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:00] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:00,370] Trial 9 finished with value: 632468822.3807085 and parameters: {'num_round': 271, 'eta': 0.22937409483316445, 'reg_lambda': 2.248799572112884, 'reg_alpha': 1.7837419296721442}. Best is trial 9 with value: 632468822.3807085.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:00] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:00,454] Trial 10 finished with value: 2220709366.6396246 and parameters: {'num_round': 407, 'eta': 0.04362822699923159, 'reg_lambda': 2.8531991101109115, 'reg_alpha': 1.7429698467614982}. Best is trial 9 with value: 632468822.3807085.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:00] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:00,528] Trial 11 finished with value: 638500566.1860484 and parameters: {'num_round': 373, 'eta': 0.2738000127517943, 'reg_lambda': 2.107934533638946, 'reg_alpha': 1.9123678954908376}. Best is trial 9 with value: 632468822.3807085.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:00] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:00,605] Trial 12 finished with value: 635728052.5575284 and parameters: {'num_round': 494, 'eta': 0.23327275172554296, 'reg_lambda': 2.291977751354426, 'reg_alpha': 2.881650887886602}. Best is trial 9 with value: 632468822.3807085.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:00] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:00,682] Trial 13 finished with value: 635909075.4434174 and parameters: {'num_round': 203, 'eta': 0.2977533852304345, 'reg_lambda': 2.4196717688991205, 'reg_alpha': 2.297109648634682}. Best is trial 9 with value: 632468822.3807085.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:00] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:00,756] Trial 14 finished with value: 651878363.6579856 and parameters: {'num_round': 322, 'eta': 0.2202121950747252, 'reg_lambda': 1.6770604203504473, 'reg_alpha': 1.4789107812536404}. Best is trial 9 with value: 632468822.3807085.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:00] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:00,855] Trial 15 finished with value: 3139065811.531143 and parameters: {'num_round': 302, 'eta': 0.018464149146318, 'reg_lambda': 2.589010389968091, 'reg_alpha': 0.9362014562424688}. Best is trial 9 with value: 632468822.3807085.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:00] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:00,925] Trial 16 finished with value: 652697295.0877061 and parameters: {'num_round': 186, 'eta': 0.23619153121271833, 'reg_lambda': 1.9333772874479807, 'reg_alpha': 1.8812376925729086}. Best is trial 9 with value: 632468822.3807085.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:00] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:00,999] Trial 17 finished with value: 1359149606.886827 and parameters: {'num_round': 250, 'eta': 0.07386337967743244, 'reg_lambda': 1.3753367913193764, 'reg_alpha': 2.5801958091761814}. Best is trial 9 with value: 632468822.3807085.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:01] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:01,072] Trial 18 finished with value: 671218968.7523521 and parameters: {'num_round': 351, 'eta': 0.20854267880080476, 'reg_lambda': 1.3231311920211002, 'reg_alpha': 2.116628821046287}. Best is trial 9 with value: 632468822.3807085.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:01] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:01,145] Trial 19 finished with value: 635427481.1511858 and parameters: {'num_round': 479, 'eta': 0.25663342075964923, 'reg_lambda': 2.567642282518829, 'reg_alpha': 1.6274580982777471}. Best is trial 9 with value: 632468822.3807085.\n",
            "[I 2024-01-26 02:32:01,177] A new study created in memory with name: no-name-c39d96e7-3cef-4407-9f03-ad643e5828a9\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:01] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:01,257] Trial 0 finished with value: 87326946.11654168 and parameters: {'num_round': 496, 'eta': 0.09325384257146427, 'reg_lambda': 0.05843382388587537, 'reg_alpha': 1.9536594342973448}. Best is trial 0 with value: 87326946.11654168.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:01] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:01,310] Trial 1 finished with value: 60653010.622603565 and parameters: {'num_round': 309, 'eta': 0.2526019003064647, 'reg_lambda': 0.9678292753063085, 'reg_alpha': 2.679646742077143}. Best is trial 1 with value: 60653010.622603565.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:01] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:01,358] Trial 2 finished with value: 69560372.8260168 and parameters: {'num_round': 363, 'eta': 0.14547558353261025, 'reg_lambda': 2.9108882013936372, 'reg_alpha': 2.7856765447087426}. Best is trial 1 with value: 60653010.622603565.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:01] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:01,405] Trial 3 finished with value: 62744747.458725974 and parameters: {'num_round': 296, 'eta': 0.2564433658544756, 'reg_lambda': 2.6206671177403016, 'reg_alpha': 0.4288640723972579}. Best is trial 1 with value: 60653010.622603565.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:01] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:01,454] Trial 4 finished with value: 86793222.32391809 and parameters: {'num_round': 332, 'eta': 0.09463427104028105, 'reg_lambda': 0.7865957449345696, 'reg_alpha': 0.1029003122815556}. Best is trial 1 with value: 60653010.622603565.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:01] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:01,502] Trial 5 finished with value: 60683676.45965906 and parameters: {'num_round': 315, 'eta': 0.25023685496614906, 'reg_lambda': 1.4046976292196571, 'reg_alpha': 0.2294577612447053}. Best is trial 1 with value: 60653010.622603565.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:01] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:01,558] Trial 6 finished with value: 94616887.85089852 and parameters: {'num_round': 260, 'eta': 0.08125216789673277, 'reg_lambda': 0.42796636869012317, 'reg_alpha': 2.1334638648790896}. Best is trial 1 with value: 60653010.622603565.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:01] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:01,604] Trial 7 finished with value: 61836220.25412618 and parameters: {'num_round': 291, 'eta': 0.20521783568068433, 'reg_lambda': 0.4276154343428916, 'reg_alpha': 0.6315124822529636}. Best is trial 1 with value: 60653010.622603565.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:01] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:01,651] Trial 8 finished with value: 62201462.54145173 and parameters: {'num_round': 265, 'eta': 0.25863902782228676, 'reg_lambda': 2.4570735240114114, 'reg_alpha': 0.5410278442244721}. Best is trial 1 with value: 60653010.622603565.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:01] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:01,713] Trial 9 finished with value: 64592945.46815435 and parameters: {'num_round': 197, 'eta': 0.217330644855797, 'reg_lambda': 1.1952362333934743, 'reg_alpha': 1.4097664618730152}. Best is trial 1 with value: 60653010.622603565.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:01] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:01,782] Trial 10 finished with value: 187292029.32471994 and parameters: {'num_round': 114, 'eta': 0.028540888448698315, 'reg_lambda': 2.0057568380317963, 'reg_alpha': 2.9522381409506577}. Best is trial 1 with value: 60653010.622603565.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:01] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:01,860] Trial 11 finished with value: 59433044.88719377 and parameters: {'num_round': 420, 'eta': 0.29111575667972167, 'reg_lambda': 1.603130908837449, 'reg_alpha': 1.1910118701377972}. Best is trial 11 with value: 59433044.88719377.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:01] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:01,928] Trial 12 finished with value: 61813240.047485374 and parameters: {'num_round': 427, 'eta': 0.2940910392822819, 'reg_lambda': 1.825427704755791, 'reg_alpha': 1.1872043985008915}. Best is trial 11 with value: 59433044.88719377.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:01] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:01,997] Trial 13 finished with value: 59276340.20929628 and parameters: {'num_round': 406, 'eta': 0.294761737846353, 'reg_lambda': 1.1096226174626336, 'reg_alpha': 2.1619422432734443}. Best is trial 13 with value: 59276340.20929628.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:02] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:02,071] Trial 14 finished with value: 59378355.18591939 and parameters: {'num_round': 428, 'eta': 0.2933222070878657, 'reg_lambda': 1.7134070941156703, 'reg_alpha': 1.9805175577050875}. Best is trial 13 with value: 59276340.20929628.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:02] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:02,155] Trial 15 finished with value: 64488747.424991325 and parameters: {'num_round': 499, 'eta': 0.16784413131532877, 'reg_lambda': 2.2290728011156253, 'reg_alpha': 2.004424404825471}. Best is trial 13 with value: 59276340.20929628.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:02] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:02,227] Trial 16 finished with value: 62458712.95630592 and parameters: {'num_round': 407, 'eta': 0.20254254235150237, 'reg_lambda': 1.5113910255152894, 'reg_alpha': 2.3959616877534287}. Best is trial 13 with value: 59276340.20929628.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:02] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:02,300] Trial 17 finished with value: 59596835.26972435 and parameters: {'num_round': 379, 'eta': 0.2953593650921092, 'reg_lambda': 0.9765866010800701, 'reg_alpha': 1.6598619130119672}. Best is trial 13 with value: 59276340.20929628.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:02] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:02,367] Trial 18 finished with value: 66628137.13590129 and parameters: {'num_round': 461, 'eta': 0.1580080969803199, 'reg_lambda': 1.9055187168819834, 'reg_alpha': 2.406383339309961}. Best is trial 13 with value: 59276340.20929628.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:32:02] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-26 02:32:02,439] Trial 19 finished with value: 259756492.5646022 and parameters: {'num_round': 445, 'eta': 0.0066392784946981975, 'reg_lambda': 1.2467243973174864, 'reg_alpha': 1.5281487546444787}. Best is trial 13 with value: 59276340.20929628.\n"
          ]
        }
      ],
      "source": [
        "folds = 3\n",
        "kf = GroupKFold(folds)\n",
        "dfp = pd.DataFrame()\n",
        "for train_idx, test_idx in kf.split(model_data, groups=model_data['circuit']):\n",
        "  train = model_data.iloc[train_idx]\n",
        "  test = model_data.iloc[test_idx]\n",
        "  # test[target] = 0\n",
        "  xtrain = xgb.DMatrix(train.loc[:, feats], train[target])\n",
        "  xtest = xgb.DMatrix(test.loc[:, feats], test[target])\n",
        "  study = opt.create_study(direction='minimize')\n",
        "  study.optimize(tune, n_trials=20)\n",
        "  _dfp = pd.DataFrame([study.best_params])\n",
        "  dfp = pd.concat([dfp,_dfp])\n",
        "\n",
        "pp = dfp.mean().to_dict()\n",
        "p = {'objective':'reg:squarederror',}\n",
        "xgbp = {**p,**pp}\n",
        "xgbp['num_round'] = int(round(xgbp['num_round']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "C_kiiJXaLgiu",
        "outputId": "065bd26c-df89-46d9-9803-1d0c257040e1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '24px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def tune(trial):\n",
        "  p = {\n",
        "      'objective':'regression',\n",
        "      'eta':trial.suggest_float('eta', 0, 0.3),\n",
        "      'n_estimators':trial.suggest_int('n_estimators', 100,300),\n",
        "      'reg_lambda':trial.suggest_float('reg_lambda', 0, 3),\n",
        "      'reg_alpha':trial.suggest_float('reg_alpha', 0, 3),\n",
        "  }\n",
        "  model = lgb.train(p, ltrain)\n",
        "  _s = pd.Series(model.predict(test.loc[:, feats]), index=test.index)\n",
        "  loss = mean_squared_error(test[target], _s)\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kofIO8ynLgnM",
        "outputId": "505845e5-56b2-4245-e66c-12dff58500c0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '24px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:02,533] A new study created in memory with name: no-name-83a264bf-98a9-4e41-99fc-2fbb7e278f15\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003873 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:03,260] Trial 0 finished with value: 6270001123.882374 and parameters: {'eta': 0.052430702767424904, 'n_estimators': 192, 'reg_lambda': 1.08666044760867, 'reg_alpha': 1.203352264429674}. Best is trial 0 with value: 6270001123.882374.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005504 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:03,764] Trial 1 finished with value: 6287354241.764295 and parameters: {'eta': 0.07396832757438525, 'n_estimators': 153, 'reg_lambda': 2.559141885579729, 'reg_alpha': 2.7819067600764926}. Best is trial 0 with value: 6270001123.882374.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004121 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:05,452] Trial 2 finished with value: 6691554050.01278 and parameters: {'eta': 0.10129980071404522, 'n_estimators': 221, 'reg_lambda': 1.6741255655791212, 'reg_alpha': 2.7182549977804475}. Best is trial 0 with value: 6270001123.882374.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004192 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:10,178] Trial 3 finished with value: 6163696105.645647 and parameters: {'eta': 0.030225346384731996, 'n_estimators': 280, 'reg_lambda': 0.5449052959424365, 'reg_alpha': 2.774340969710995}. Best is trial 3 with value: 6163696105.645647.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003954 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:11,016] Trial 4 finished with value: 6639683401.3697195 and parameters: {'eta': 0.06961320123207275, 'n_estimators': 300, 'reg_lambda': 1.4169898836223873, 'reg_alpha': 0.4441752508147292}. Best is trial 3 with value: 6163696105.645647.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003983 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:11,763] Trial 5 finished with value: 6847500662.677566 and parameters: {'eta': 0.2339796122149567, 'n_estimators': 276, 'reg_lambda': 1.9602068197314333, 'reg_alpha': 2.477245068266542}. Best is trial 3 with value: 6163696105.645647.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004111 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:12,415] Trial 6 finished with value: 6864663098.889363 and parameters: {'eta': 0.2889212038797738, 'n_estimators': 225, 'reg_lambda': 0.9020528800221087, 'reg_alpha': 2.437086356773055}. Best is trial 3 with value: 6163696105.645647.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004857 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:12,923] Trial 7 finished with value: 6756115148.889412 and parameters: {'eta': 0.16035019105812806, 'n_estimators': 181, 'reg_lambda': 1.0672876806500473, 'reg_alpha': 0.2485303548601664}. Best is trial 3 with value: 6163696105.645647.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005533 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:13,553] Trial 8 finished with value: 5928197873.990585 and parameters: {'eta': 0.029998224816988703, 'n_estimators': 176, 'reg_lambda': 0.8906396901175098, 'reg_alpha': 0.4071964816693353}. Best is trial 8 with value: 5928197873.990585.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004050 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:14,278] Trial 9 finished with value: 6853077051.916384 and parameters: {'eta': 0.1792348652298201, 'n_estimators': 265, 'reg_lambda': 2.0377901918308985, 'reg_alpha': 2.282037719870078}. Best is trial 8 with value: 5928197873.990585.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004122 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:14,716] Trial 10 finished with value: 5770720945.934174 and parameters: {'eta': 0.013325751010671422, 'n_estimators': 111, 'reg_lambda': 0.025869886558735233, 'reg_alpha': 0.9834246468123007}. Best is trial 10 with value: 5770720945.934174.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004761 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:15,133] Trial 11 finished with value: 5783360284.678679 and parameters: {'eta': 0.010745445171310333, 'n_estimators': 108, 'reg_lambda': 0.06813270427940266, 'reg_alpha': 0.9439936443026794}. Best is trial 10 with value: 5770720945.934174.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004261 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:15,590] Trial 12 finished with value: 6270838632.125369 and parameters: {'eta': 0.004362714594908168, 'n_estimators': 108, 'reg_lambda': 0.023440157838300557, 'reg_alpha': 1.1515889676559052}. Best is trial 10 with value: 5770720945.934174.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004324 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:15,925] Trial 13 finished with value: 6328890799.328549 and parameters: {'eta': 0.11139718265096232, 'n_estimators': 100, 'reg_lambda': 0.21617349848397485, 'reg_alpha': 1.8131912130086976}. Best is trial 10 with value: 5770720945.934174.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004699 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:16,471] Trial 14 finished with value: 6154282893.840523 and parameters: {'eta': 0.004040739834953391, 'n_estimators': 134, 'reg_lambda': 0.3790592952968663, 'reg_alpha': 0.9154730959465843}. Best is trial 10 with value: 5770720945.934174.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001526 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:16,880] Trial 15 finished with value: 6592250636.127208 and parameters: {'eta': 0.12214838463911572, 'n_estimators': 129, 'reg_lambda': 0.572620061373517, 'reg_alpha': 1.6777782220977653}. Best is trial 10 with value: 5770720945.934174.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003993 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:17,324] Trial 16 finished with value: 6736820084.879341 and parameters: {'eta': 0.2004146819443693, 'n_estimators': 149, 'reg_lambda': 0.07891069149310725, 'reg_alpha': 0.8159003849447439}. Best is trial 10 with value: 5770720945.934174.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003878 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:17,747] Trial 17 finished with value: 5875886527.553251 and parameters: {'eta': 0.042022729939315065, 'n_estimators': 113, 'reg_lambda': 2.9409016838941913, 'reg_alpha': 1.4245895484906048}. Best is trial 10 with value: 5770720945.934174.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005392 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:18,259] Trial 18 finished with value: 6539294070.821003 and parameters: {'eta': 0.09582042950468111, 'n_estimators': 160, 'reg_lambda': 0.6977712785487303, 'reg_alpha': 0.001565111853558676}. Best is trial 10 with value: 5770720945.934174.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004287 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94561.504396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:18,681] Trial 19 finished with value: 6615290574.827512 and parameters: {'eta': 0.14077971594186356, 'n_estimators': 127, 'reg_lambda': 1.4256881304671993, 'reg_alpha': 0.7015905232546326}. Best is trial 10 with value: 5770720945.934174.\n",
            "[I 2024-01-26 02:32:18,717] A new study created in memory with name: no-name-61a6ebd6-292e-40b2-a41a-6642d092c752\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003644 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:19,393] Trial 0 finished with value: 1666900082.9185438 and parameters: {'eta': 0.08884079069787698, 'n_estimators': 220, 'reg_lambda': 0.2504779693935276, 'reg_alpha': 2.771409127062565}. Best is trial 0 with value: 1666900082.9185438.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003944 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:19,877] Trial 1 finished with value: 1444969634.730207 and parameters: {'eta': 0.21910146842961406, 'n_estimators': 118, 'reg_lambda': 1.7127239813643285, 'reg_alpha': 0.4813179524693647}. Best is trial 1 with value: 1444969634.730207.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006132 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:22,638] Trial 2 finished with value: 1590673022.8103 and parameters: {'eta': 0.27401095758371763, 'n_estimators': 200, 'reg_lambda': 1.6708770262465602, 'reg_alpha': 2.6810624921018453}. Best is trial 1 with value: 1444969634.730207.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004361 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:23,333] Trial 3 finished with value: 1853566860.774649 and parameters: {'eta': 0.040165313499455534, 'n_estimators': 223, 'reg_lambda': 1.3347037006543752, 'reg_alpha': 2.9583959468159975}. Best is trial 1 with value: 1444969634.730207.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005852 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:23,749] Trial 4 finished with value: 1995028832.599473 and parameters: {'eta': 0.020870853674739197, 'n_estimators': 105, 'reg_lambda': 0.6802349009452598, 'reg_alpha': 0.7162030377496685}. Best is trial 1 with value: 1444969634.730207.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004599 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:24,479] Trial 5 finished with value: 1523989703.1234863 and parameters: {'eta': 0.08361223849539036, 'n_estimators': 253, 'reg_lambda': 1.2413629135620938, 'reg_alpha': 1.2269720552057004}. Best is trial 1 with value: 1444969634.730207.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005040 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:24,895] Trial 6 finished with value: 1638577378.8646588 and parameters: {'eta': 0.18447066335900503, 'n_estimators': 141, 'reg_lambda': 2.1860703208741796, 'reg_alpha': 1.130184988349046}. Best is trial 1 with value: 1444969634.730207.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004034 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:25,524] Trial 7 finished with value: 1411450488.401203 and parameters: {'eta': 0.23385380638546688, 'n_estimators': 241, 'reg_lambda': 2.412776566181092, 'reg_alpha': 2.4208636537303305}. Best is trial 7 with value: 1411450488.401203.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003928 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:26,023] Trial 8 finished with value: 1429278068.1970303 and parameters: {'eta': 0.20816724254327795, 'n_estimators': 174, 'reg_lambda': 0.5831917435742193, 'reg_alpha': 2.796237166076153}. Best is trial 7 with value: 1411450488.401203.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004885 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:26,559] Trial 9 finished with value: 1490578553.6385212 and parameters: {'eta': 0.24309658671170342, 'n_estimators': 205, 'reg_lambda': 1.1415700367247363, 'reg_alpha': 0.2537543667200346}. Best is trial 7 with value: 1411450488.401203.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004018 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:27,321] Trial 10 finished with value: 1641421105.3601408 and parameters: {'eta': 0.29816883768580105, 'n_estimators': 283, 'reg_lambda': 2.832233768244286, 'reg_alpha': 2.0359592280540877}. Best is trial 7 with value: 1411450488.401203.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003994 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:27,789] Trial 11 finished with value: 1708404622.9532292 and parameters: {'eta': 0.15586780917751905, 'n_estimators': 158, 'reg_lambda': 2.939372431272134, 'reg_alpha': 2.018907864014997}. Best is trial 7 with value: 1411450488.401203.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004151 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:28,285] Trial 12 finished with value: 1524232025.3035283 and parameters: {'eta': 0.20773836622960343, 'n_estimators': 170, 'reg_lambda': 2.346775683024342, 'reg_alpha': 2.161944585927678}. Best is trial 7 with value: 1411450488.401203.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004486 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:29,010] Trial 13 finished with value: 1677747797.8445673 and parameters: {'eta': 0.14663239519006788, 'n_estimators': 257, 'reg_lambda': 0.025785313445235936, 'reg_alpha': 2.493977073130415}. Best is trial 7 with value: 1411450488.401203.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003994 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:29,511] Trial 14 finished with value: 1682837714.1127062 and parameters: {'eta': 0.2513337108357143, 'n_estimators': 179, 'reg_lambda': 0.720871856972402, 'reg_alpha': 1.6298769407846958}. Best is trial 7 with value: 1411450488.401203.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003992 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:30,209] Trial 15 finished with value: 1387688510.196068 and parameters: {'eta': 0.16742076173320308, 'n_estimators': 248, 'reg_lambda': 1.8655199685088708, 'reg_alpha': 2.3633993912014346}. Best is trial 15 with value: 1387688510.196068.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003880 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:31,050] Trial 16 finished with value: 1705336189.6189933 and parameters: {'eta': 0.13585095607626313, 'n_estimators': 299, 'reg_lambda': 2.18839243694147, 'reg_alpha': 2.2751541671698354}. Best is trial 15 with value: 1387688510.196068.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001678 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:31,750] Trial 17 finished with value: 1950635149.0762575 and parameters: {'eta': 0.11136514945230026, 'n_estimators': 251, 'reg_lambda': 2.487085672250222, 'reg_alpha': 1.752904717942849}. Best is trial 15 with value: 1387688510.196068.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003940 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:32,545] Trial 18 finished with value: 1629322094.3794632 and parameters: {'eta': 0.18637972491710364, 'n_estimators': 236, 'reg_lambda': 1.9975993413777102, 'reg_alpha': 2.4268670419547322}. Best is trial 15 with value: 1387688510.196068.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004017 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91127.516650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:35,648] Trial 19 finished with value: 1447210688.7332075 and parameters: {'eta': 0.17116908498021566, 'n_estimators': 272, 'reg_lambda': 1.881150338207441, 'reg_alpha': 1.3629904532924175}. Best is trial 15 with value: 1387688510.196068.\n",
            "[I 2024-01-26 02:32:35,683] A new study created in memory with name: no-name-225bbe03-b1b3-4d54-a4a7-389d5ee57da9\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004106 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:36,100] Trial 0 finished with value: 70756917.64599748 and parameters: {'eta': 0.2541361991507879, 'n_estimators': 128, 'reg_lambda': 2.6703499332205465, 'reg_alpha': 1.1958468468827226}. Best is trial 0 with value: 70756917.64599748.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003964 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:36,521] Trial 1 finished with value: 61808470.083944134 and parameters: {'eta': 0.11546101036489888, 'n_estimators': 139, 'reg_lambda': 1.7971889922151387, 'reg_alpha': 0.8468336044706465}. Best is trial 1 with value: 61808470.083944134.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008186 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:37,056] Trial 2 finished with value: 81594574.27573492 and parameters: {'eta': 0.25720470198405976, 'n_estimators': 189, 'reg_lambda': 0.3364835896168522, 'reg_alpha': 0.9165239209014819}. Best is trial 1 with value: 61808470.083944134.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006671 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:37,627] Trial 3 finished with value: 79403187.30172229 and parameters: {'eta': 0.2938477113331296, 'n_estimators': 197, 'reg_lambda': 1.4458336488454206, 'reg_alpha': 1.3785481902907777}. Best is trial 1 with value: 61808470.083944134.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005757 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:38,027] Trial 4 finished with value: 61572593.01350487 and parameters: {'eta': 0.15850738768506206, 'n_estimators': 137, 'reg_lambda': 0.3220835695616876, 'reg_alpha': 0.473725261606614}. Best is trial 4 with value: 61572593.01350487.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003532 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:38,473] Trial 5 finished with value: 69016621.54071642 and parameters: {'eta': 0.2124827908939876, 'n_estimators': 147, 'reg_lambda': 0.920203914974678, 'reg_alpha': 1.5316320695263785}. Best is trial 4 with value: 61572593.01350487.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007550 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:38,889] Trial 6 finished with value: 61741847.87987196 and parameters: {'eta': 0.10666492753179593, 'n_estimators': 133, 'reg_lambda': 2.854919764745301, 'reg_alpha': 1.4652933697108512}. Best is trial 4 with value: 61572593.01350487.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005180 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:39,475] Trial 7 finished with value: 64265809.733313344 and parameters: {'eta': 0.14171800078944172, 'n_estimators': 201, 'reg_lambda': 2.7815081566467024, 'reg_alpha': 2.091051776664411}. Best is trial 4 with value: 61572593.01350487.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011893 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:40,030] Trial 8 finished with value: 66784370.732156016 and parameters: {'eta': 0.12683789186213587, 'n_estimators': 190, 'reg_lambda': 2.201345313327661, 'reg_alpha': 1.6944078462665946}. Best is trial 4 with value: 61572593.01350487.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004667 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:40,387] Trial 9 finished with value: 71968076.44238485 and parameters: {'eta': 0.2587466412212017, 'n_estimators': 109, 'reg_lambda': 0.69405506328226, 'reg_alpha': 1.0079645343577917}. Best is trial 4 with value: 61572593.01350487.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004058 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:41,489] Trial 10 finished with value: 62655911.11765465 and parameters: {'eta': 0.005457630304241817, 'n_estimators': 298, 'reg_lambda': 0.013893421754075097, 'reg_alpha': 0.051098720674074505}. Best is trial 4 with value: 61572593.01350487.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004104 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:42,033] Trial 11 finished with value: 62962701.36017844 and parameters: {'eta': 0.06401566097341223, 'n_estimators': 160, 'reg_lambda': 1.2073828629864045, 'reg_alpha': 2.7527452586206937}. Best is trial 4 with value: 61572593.01350487.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004041 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:42,730] Trial 12 finished with value: 72924407.97850527 and parameters: {'eta': 0.1881248263455069, 'n_estimators': 240, 'reg_lambda': 2.072188446894896, 'reg_alpha': 0.18514946230584478}. Best is trial 4 with value: 61572593.01350487.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004056 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:43,095] Trial 13 finished with value: 62070345.12686819 and parameters: {'eta': 0.07917767982120898, 'n_estimators': 100, 'reg_lambda': 2.9150124353628604, 'reg_alpha': 0.4909885637903084}. Best is trial 4 with value: 61572593.01350487.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004189 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:44,173] Trial 14 finished with value: 74618830.93599577 and parameters: {'eta': 0.18314087909829044, 'n_estimators': 168, 'reg_lambda': 2.326985792174997, 'reg_alpha': 2.187361466782436}. Best is trial 4 with value: 61572593.01350487.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001457 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:44,905] Trial 15 finished with value: 61946045.74087597 and parameters: {'eta': 0.045158602873861774, 'n_estimators': 228, 'reg_lambda': 0.4651326858562501, 'reg_alpha': 0.5768663032265612}. Best is trial 4 with value: 61572593.01350487.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004114 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:45,593] Trial 16 finished with value: 62771630.37566516 and parameters: {'eta': 0.10747690870853797, 'n_estimators': 124, 'reg_lambda': 1.699975110204641, 'reg_alpha': 2.901485109627854}. Best is trial 4 with value: 61572593.01350487.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.159474 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:48,333] Trial 17 finished with value: 70835308.87926015 and parameters: {'eta': 0.16821172999664652, 'n_estimators': 162, 'reg_lambda': 1.164695824944642, 'reg_alpha': 1.9111256536285182}. Best is trial 4 with value: 61572593.01350487.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004162 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:49,309] Trial 18 finished with value: 64039985.662779056 and parameters: {'eta': 0.013958037258312878, 'n_estimators': 277, 'reg_lambda': 0.02846054150568378, 'reg_alpha': 2.4746067252933677}. Best is trial 4 with value: 61572593.01350487.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004108 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1366\n",
            "[LightGBM] [Info] Number of data points in the train set: 19984, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 97692.863441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:49,736] Trial 19 finished with value: 60891136.95603324 and parameters: {'eta': 0.08483650842469129, 'n_estimators': 118, 'reg_lambda': 2.5118298975833757, 'reg_alpha': 0.3838313451059572}. Best is trial 19 with value: 60891136.95603324.\n"
          ]
        }
      ],
      "source": [
        "dfp = pd.DataFrame()\n",
        "for train_idx, test_idx in kf.split(model_data, groups=model_data['circuit']):\n",
        "  train = model_data.iloc[train_idx]\n",
        "  test = model_data.iloc[test_idx]\n",
        "  # test[target] = 0\n",
        "  xtrain = xgb.DMatrix(train.loc[:, feats], train[target])\n",
        "  xtest = xgb.DMatrix(test.loc[:, feats], test[target])\n",
        "  ltrain = lgb.Dataset(train.loc[:, feats], train[target])\n",
        "  ltest = lgb.Dataset(test.loc[:, feats], test[target])\n",
        "  study = opt.create_study(direction='minimize')\n",
        "  study.optimize(tune, n_trials=20)\n",
        "  _dfp = pd.DataFrame([study.best_params])\n",
        "  dfp = pd.concat([dfp,_dfp])\n",
        "\n",
        "pp = dfp.mean().to_dict()\n",
        "p = {'objective':'regression',}\n",
        "lgbp = {**p,**pp}\n",
        "lgbp['n_estimators'] = int(round(lgbp['n_estimators']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "T49KgZ71LgsU",
        "outputId": "485383fd-653c-4feb-f502-fea716ab7f1a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '24px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def tune(trial):\n",
        "  p = {\n",
        "      'n_estimators':trial.suggest_int('n_estimators', 100,200),\n",
        "      'eta':trial.suggest_float('eta', 0, 0.3),\n",
        "      'reg_lambda':trial.suggest_float('reg_lambda', 0, 3),\n",
        "  }\n",
        "  model = cb.CatBoostRegressor(**p, verbose=False)\n",
        "  model.fit(train.loc[:, feats], train[target])\n",
        "  _s = pd.Series(model.predict(test.loc[:, feats]), index=test.index)\n",
        "  loss = mean_squared_error(test[target], _s)\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ux124WmaMeQO",
        "outputId": "8aef457f-8aa4-48eb-b8ef-84edccb94ab5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '24px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-26 02:32:49,834] A new study created in memory with name: no-name-fcdd6b2d-f492-4523-82f1-ac5521b7b146\n",
            "[I 2024-01-26 02:32:50,672] Trial 0 finished with value: 7540700182.184094 and parameters: {'n_estimators': 147, 'eta': 0.1689656205895288, 'reg_lambda': 1.8726964106536799}. Best is trial 0 with value: 7540700182.184094.\n",
            "[I 2024-01-26 02:32:51,411] Trial 1 finished with value: 7806565529.613244 and parameters: {'n_estimators': 155, 'eta': 0.03371525441832829, 'reg_lambda': 1.9439643083150284}. Best is trial 0 with value: 7540700182.184094.\n",
            "[I 2024-01-26 02:32:52,353] Trial 2 finished with value: 7391136926.193222 and parameters: {'n_estimators': 186, 'eta': 0.23629557252967168, 'reg_lambda': 1.3978553516118848}. Best is trial 2 with value: 7391136926.193222.\n",
            "[I 2024-01-26 02:32:53,459] Trial 3 finished with value: 7340905286.281172 and parameters: {'n_estimators': 130, 'eta': 0.20523994669733206, 'reg_lambda': 1.4044000855482337}. Best is trial 3 with value: 7340905286.281172.\n",
            "[I 2024-01-26 02:32:54,494] Trial 4 finished with value: 8575853438.308794 and parameters: {'n_estimators': 109, 'eta': 0.2651869276573356, 'reg_lambda': 0.6596845199393483}. Best is trial 3 with value: 7340905286.281172.\n",
            "[I 2024-01-26 02:32:55,109] Trial 5 finished with value: 7810642167.705757 and parameters: {'n_estimators': 124, 'eta': 0.024407971749434477, 'reg_lambda': 1.190926893293851}. Best is trial 3 with value: 7340905286.281172.\n",
            "[I 2024-01-26 02:32:55,676] Trial 6 finished with value: 7587170623.502745 and parameters: {'n_estimators': 111, 'eta': 0.10293703513129897, 'reg_lambda': 1.9653856155034755}. Best is trial 3 with value: 7340905286.281172.\n",
            "[I 2024-01-26 02:32:56,621] Trial 7 finished with value: 7829063119.233728 and parameters: {'n_estimators': 199, 'eta': 0.02818179995186828, 'reg_lambda': 0.8166743848726211}. Best is trial 3 with value: 7340905286.281172.\n",
            "[I 2024-01-26 02:32:57,370] Trial 8 finished with value: 7516329088.597534 and parameters: {'n_estimators': 151, 'eta': 0.16004649301848023, 'reg_lambda': 2.040707321786888}. Best is trial 3 with value: 7340905286.281172.\n",
            "[I 2024-01-26 02:32:58,140] Trial 9 finished with value: 7731723008.564913 and parameters: {'n_estimators': 153, 'eta': 0.10687865560296715, 'reg_lambda': 2.350994526997039}. Best is trial 3 with value: 7340905286.281172.\n",
            "[I 2024-01-26 02:32:58,208] A new study created in memory with name: no-name-68018b86-0e98-44ad-86bf-7aefff3dc793\n",
            "[I 2024-01-26 02:33:00,338] Trial 0 finished with value: 3691041498.063435 and parameters: {'n_estimators': 200, 'eta': 0.26162255536819934, 'reg_lambda': 1.6580231407368513}. Best is trial 0 with value: 3691041498.063435.\n",
            "[I 2024-01-26 02:33:01,757] Trial 1 finished with value: 3581336078.997461 and parameters: {'n_estimators': 164, 'eta': 0.02851910987176357, 'reg_lambda': 0.5897961914494327}. Best is trial 1 with value: 3581336078.997461.\n",
            "[I 2024-01-26 02:33:02,317] Trial 2 finished with value: 3393306735.5820103 and parameters: {'n_estimators': 111, 'eta': 0.13762141153297602, 'reg_lambda': 2.9773755487192672}. Best is trial 2 with value: 3393306735.5820103.\n",
            "[I 2024-01-26 02:33:02,842] Trial 3 finished with value: 4116332021.8258758 and parameters: {'n_estimators': 105, 'eta': 0.25285234588591193, 'reg_lambda': 1.0319263830224914}. Best is trial 2 with value: 3393306735.5820103.\n",
            "[I 2024-01-26 02:33:03,738] Trial 4 finished with value: 3662268909.9216695 and parameters: {'n_estimators': 186, 'eta': 0.03236343457754833, 'reg_lambda': 2.3092960157722744}. Best is trial 2 with value: 3393306735.5820103.\n",
            "[I 2024-01-26 02:33:04,321] Trial 5 finished with value: 3595548865.357844 and parameters: {'n_estimators': 108, 'eta': 0.23604459763745875, 'reg_lambda': 1.1338857436326095}. Best is trial 2 with value: 3393306735.5820103.\n",
            "[I 2024-01-26 02:33:05,308] Trial 6 finished with value: 3839130075.1117 and parameters: {'n_estimators': 193, 'eta': 0.09016120427015649, 'reg_lambda': 2.4329330212877256}. Best is trial 2 with value: 3393306735.5820103.\n",
            "[I 2024-01-26 02:33:06,268] Trial 7 finished with value: 3479136775.261467 and parameters: {'n_estimators': 192, 'eta': 0.05388670706034364, 'reg_lambda': 1.6046886525051454}. Best is trial 2 with value: 3393306735.5820103.\n",
            "[I 2024-01-26 02:33:07,012] Trial 8 finished with value: 3755101936.2261305 and parameters: {'n_estimators': 147, 'eta': 0.2874352067512365, 'reg_lambda': 1.6784523683318493}. Best is trial 2 with value: 3393306735.5820103.\n",
            "[I 2024-01-26 02:33:08,061] Trial 9 finished with value: 4021476934.517019 and parameters: {'n_estimators': 199, 'eta': 0.28767600423115613, 'reg_lambda': 0.2710923001615233}. Best is trial 2 with value: 3393306735.5820103.\n",
            "[I 2024-01-26 02:33:08,101] A new study created in memory with name: no-name-5a7a88cf-5b47-4381-9361-957a165c58cb\n",
            "[I 2024-01-26 02:33:09,030] Trial 0 finished with value: 86353013.86736363 and parameters: {'n_estimators': 193, 'eta': 0.1499469684694636, 'reg_lambda': 1.6987567628913491}. Best is trial 0 with value: 86353013.86736363.\n",
            "[I 2024-01-26 02:33:09,779] Trial 1 finished with value: 283490078.79684037 and parameters: {'n_estimators': 145, 'eta': 0.0002876777992604329, 'reg_lambda': 0.7220852800838814}. Best is trial 0 with value: 86353013.86736363.\n",
            "[I 2024-01-26 02:33:10,599] Trial 2 finished with value: 100133862.25916405 and parameters: {'n_estimators': 158, 'eta': 0.16175675280220614, 'reg_lambda': 2.5395385805326782}. Best is trial 0 with value: 86353013.86736363.\n",
            "[I 2024-01-26 02:33:11,244] Trial 3 finished with value: 85001891.40439579 and parameters: {'n_estimators': 129, 'eta': 0.17398381047908337, 'reg_lambda': 2.65270560565234}. Best is trial 3 with value: 85001891.40439579.\n",
            "[I 2024-01-26 02:33:12,369] Trial 4 finished with value: 78175529.6422849 and parameters: {'n_estimators': 119, 'eta': 0.11633704529054027, 'reg_lambda': 1.8782638747995546}. Best is trial 4 with value: 78175529.6422849.\n",
            "[I 2024-01-26 02:33:14,188] Trial 5 finished with value: 112158431.67422113 and parameters: {'n_estimators': 157, 'eta': 0.13179599287962063, 'reg_lambda': 1.406824631011741}. Best is trial 4 with value: 78175529.6422849.\n",
            "[I 2024-01-26 02:33:15,259] Trial 6 finished with value: 92995556.1997743 and parameters: {'n_estimators': 130, 'eta': 0.20107433689702647, 'reg_lambda': 0.6428117310622115}. Best is trial 4 with value: 78175529.6422849.\n",
            "[I 2024-01-26 02:33:16,051] Trial 7 finished with value: 70516866.52340226 and parameters: {'n_estimators': 154, 'eta': 0.03472122077580871, 'reg_lambda': 1.2343529984443369}. Best is trial 7 with value: 70516866.52340226.\n",
            "[I 2024-01-26 02:33:16,867] Trial 8 finished with value: 163810068.39511624 and parameters: {'n_estimators': 160, 'eta': 0.01041810875262078, 'reg_lambda': 2.9829179383406115}. Best is trial 7 with value: 70516866.52340226.\n",
            "[I 2024-01-26 02:33:17,447] Trial 9 finished with value: 81549052.7624413 and parameters: {'n_estimators': 118, 'eta': 0.17168619276637254, 'reg_lambda': 2.7082533141952085}. Best is trial 7 with value: 70516866.52340226.\n"
          ]
        }
      ],
      "source": [
        "dfp = pd.DataFrame()\n",
        "for train_idx, test_idx in kf.split(model_data, groups=model_data['circuit']):\n",
        "  train = model_data.iloc[train_idx]\n",
        "  test = model_data.iloc[test_idx]\n",
        "  # test[target] = 0\n",
        "  xtrain = xgb.DMatrix(train.loc[:, feats], train[target])\n",
        "  xtest = xgb.DMatrix(test.loc[:, feats], test[target])\n",
        "  ltrain = lgb.Dataset(train.loc[:, feats], train[target])\n",
        "  ltest = lgb.Dataset(test.loc[:, feats], test[target])\n",
        "\n",
        "  study = opt.create_study(direction='minimize')\n",
        "  study.optimize(tune, n_trials=10)\n",
        "  _dfp = pd.DataFrame([study.best_params])\n",
        "  dfp = pd.concat([dfp,_dfp])\n",
        "\n",
        "cbp = dfp.mean().to_dict()\n",
        "cbp['n_estimators'] = int(round(cbp['n_estimators']))\n",
        "# cbp = {**p,**pp}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VmFyUqwpNJHw",
        "outputId": "da48265a-9be2-4f6d-c728-fad75bc1f3f9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '24px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-781352b8eaed>:3: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  out1 = pd.Series()\n",
            "<ipython-input-18-781352b8eaed>:4: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  out2 = pd.Series()\n",
            "<ipython-input-18-781352b8eaed>:5: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  out3 = pd.Series()\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:33:17] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 51005.4747101\ttotal: 5.61ms\tremaining: 735ms\n",
            "1:\tlearn: 46632.5201617\ttotal: 11ms\tremaining: 718ms\n",
            "2:\tlearn: 42707.1513397\ttotal: 17.1ms\tremaining: 735ms\n",
            "3:\tlearn: 39193.7951051\ttotal: 25.4ms\tremaining: 812ms\n",
            "4:\tlearn: 36125.3608856\ttotal: 30.5ms\tremaining: 775ms\n",
            "5:\tlearn: 33450.1302281\ttotal: 35.2ms\tremaining: 739ms\n",
            "6:\tlearn: 30902.2976784\ttotal: 40.1ms\tremaining: 716ms\n",
            "7:\tlearn: 28836.9012686\ttotal: 49.7ms\tremaining: 770ms\n",
            "8:\tlearn: 26821.4396041\ttotal: 55.1ms\tremaining: 753ms\n",
            "9:\tlearn: 24942.8330255\ttotal: 60ms\tremaining: 732ms\n",
            "10:\tlearn: 23306.5057565\ttotal: 65.1ms\tremaining: 716ms\n",
            "11:\tlearn: 21918.2763257\ttotal: 69.9ms\tremaining: 699ms\n",
            "12:\tlearn: 20753.3297302\ttotal: 74.7ms\tremaining: 684ms\n",
            "13:\tlearn: 19691.6720339\ttotal: 79.8ms\tremaining: 672ms\n",
            "14:\tlearn: 18796.4400026\ttotal: 85ms\tremaining: 663ms\n",
            "15:\tlearn: 18008.6776690\ttotal: 89.7ms\tremaining: 650ms\n",
            "16:\tlearn: 17289.8345771\ttotal: 94.3ms\tremaining: 638ms\n",
            "17:\tlearn: 16624.0999793\ttotal: 99.1ms\tremaining: 627ms\n",
            "18:\tlearn: 15992.5249595\ttotal: 104ms\tremaining: 621ms\n",
            "19:\tlearn: 15304.5932595\ttotal: 109ms\tremaining: 613ms\n",
            "20:\tlearn: 14816.0481267\ttotal: 114ms\tremaining: 604ms\n",
            "21:\tlearn: 14333.2213503\ttotal: 120ms\tremaining: 598ms\n",
            "22:\tlearn: 13931.3699611\ttotal: 125ms\tremaining: 590ms\n",
            "23:\tlearn: 13528.4097285\ttotal: 130ms\tremaining: 584ms\n",
            "24:\tlearn: 13205.0077549\ttotal: 135ms\tremaining: 576ms\n",
            "25:\tlearn: 12838.7852813\ttotal: 139ms\tremaining: 568ms\n",
            "26:\tlearn: 12514.9808218\ttotal: 144ms\tremaining: 562ms\n",
            "27:\tlearn: 12254.9141614\ttotal: 149ms\tremaining: 554ms\n",
            "28:\tlearn: 12041.9657156\ttotal: 154ms\tremaining: 548ms\n",
            "29:\tlearn: 11806.2296092\ttotal: 160ms\tremaining: 543ms\n",
            "30:\tlearn: 11601.4490524\ttotal: 165ms\tremaining: 536ms\n",
            "31:\tlearn: 11318.2729727\ttotal: 170ms\tremaining: 530ms\n",
            "32:\tlearn: 11107.2635025\ttotal: 175ms\tremaining: 525ms\n",
            "33:\tlearn: 10874.4303803\ttotal: 180ms\tremaining: 519ms\n",
            "34:\tlearn: 10740.1253889\ttotal: 185ms\tremaining: 513ms\n",
            "35:\tlearn: 10580.8655776\ttotal: 191ms\tremaining: 509ms\n",
            "36:\tlearn: 10470.5878644\ttotal: 196ms\tremaining: 503ms\n",
            "37:\tlearn: 10362.2479187\ttotal: 207ms\tremaining: 511ms\n",
            "38:\tlearn: 10236.4857992\ttotal: 212ms\tremaining: 506ms\n",
            "39:\tlearn: 10135.1701097\ttotal: 217ms\tremaining: 500ms\n",
            "40:\tlearn: 10015.3048552\ttotal: 222ms\tremaining: 493ms\n",
            "41:\tlearn: 9954.1720508\ttotal: 227ms\tremaining: 487ms\n",
            "42:\tlearn: 9769.9201386\ttotal: 232ms\tremaining: 481ms\n",
            "43:\tlearn: 9624.8032890\ttotal: 237ms\tremaining: 475ms\n",
            "44:\tlearn: 9475.5219140\ttotal: 243ms\tremaining: 470ms\n",
            "45:\tlearn: 9425.3430739\ttotal: 248ms\tremaining: 464ms\n",
            "46:\tlearn: 9316.4003117\ttotal: 255ms\tremaining: 462ms\n",
            "47:\tlearn: 9216.4793818\ttotal: 263ms\tremaining: 461ms\n",
            "48:\tlearn: 9138.3510967\ttotal: 268ms\tremaining: 454ms\n",
            "49:\tlearn: 9104.9213391\ttotal: 273ms\tremaining: 448ms\n",
            "50:\tlearn: 9048.8951239\ttotal: 278ms\tremaining: 442ms\n",
            "51:\tlearn: 8989.7601663\ttotal: 283ms\tremaining: 435ms\n",
            "52:\tlearn: 8884.3520006\ttotal: 288ms\tremaining: 430ms\n",
            "53:\tlearn: 8854.2623404\ttotal: 294ms\tremaining: 424ms\n",
            "54:\tlearn: 8749.2748318\ttotal: 298ms\tremaining: 417ms\n",
            "55:\tlearn: 8670.4983704\ttotal: 303ms\tremaining: 411ms\n",
            "56:\tlearn: 8601.7369860\ttotal: 309ms\tremaining: 406ms\n",
            "57:\tlearn: 8540.0418179\ttotal: 314ms\tremaining: 401ms\n",
            "58:\tlearn: 8507.5827621\ttotal: 319ms\tremaining: 395ms\n",
            "59:\tlearn: 8475.6144630\ttotal: 324ms\tremaining: 389ms\n",
            "60:\tlearn: 8442.2998384\ttotal: 336ms\tremaining: 391ms\n",
            "61:\tlearn: 8345.9305812\ttotal: 342ms\tremaining: 386ms\n",
            "62:\tlearn: 8316.1238337\ttotal: 346ms\tremaining: 379ms\n",
            "63:\tlearn: 8239.9494552\ttotal: 351ms\tremaining: 373ms\n",
            "64:\tlearn: 8210.2968300\ttotal: 356ms\tremaining: 367ms\n",
            "65:\tlearn: 8155.4442279\ttotal: 361ms\tremaining: 361ms\n",
            "66:\tlearn: 8082.0081537\ttotal: 367ms\tremaining: 356ms\n",
            "67:\tlearn: 7993.3745765\ttotal: 372ms\tremaining: 350ms\n",
            "68:\tlearn: 7939.1838569\ttotal: 377ms\tremaining: 344ms\n",
            "69:\tlearn: 7869.3118468\ttotal: 382ms\tremaining: 338ms\n",
            "70:\tlearn: 7784.7325849\ttotal: 392ms\tremaining: 337ms\n",
            "71:\tlearn: 7737.2174670\ttotal: 397ms\tremaining: 331ms\n",
            "72:\tlearn: 7682.2206699\ttotal: 407ms\tremaining: 329ms\n",
            "73:\tlearn: 7663.2592866\ttotal: 412ms\tremaining: 323ms\n",
            "74:\tlearn: 7606.0107497\ttotal: 417ms\tremaining: 317ms\n",
            "75:\tlearn: 7581.0127054\ttotal: 422ms\tremaining: 311ms\n",
            "76:\tlearn: 7541.4935611\ttotal: 427ms\tremaining: 305ms\n",
            "77:\tlearn: 7511.2223005\ttotal: 432ms\tremaining: 299ms\n",
            "78:\tlearn: 7484.3104017\ttotal: 437ms\tremaining: 293ms\n",
            "79:\tlearn: 7426.8519368\ttotal: 442ms\tremaining: 287ms\n",
            "80:\tlearn: 7399.1311002\ttotal: 447ms\tremaining: 282ms\n",
            "81:\tlearn: 7366.2468707\ttotal: 452ms\tremaining: 276ms\n",
            "82:\tlearn: 7355.0083712\ttotal: 457ms\tremaining: 270ms\n",
            "83:\tlearn: 7339.7491068\ttotal: 462ms\tremaining: 264ms\n",
            "84:\tlearn: 7302.3796086\ttotal: 466ms\tremaining: 258ms\n",
            "85:\tlearn: 7285.8984803\ttotal: 471ms\tremaining: 252ms\n",
            "86:\tlearn: 7252.0240702\ttotal: 476ms\tremaining: 246ms\n",
            "87:\tlearn: 7201.0738565\ttotal: 481ms\tremaining: 240ms\n",
            "88:\tlearn: 7158.4765030\ttotal: 486ms\tremaining: 235ms\n",
            "89:\tlearn: 7100.8469678\ttotal: 493ms\tremaining: 230ms\n",
            "90:\tlearn: 7059.4536224\ttotal: 499ms\tremaining: 225ms\n",
            "91:\tlearn: 7027.1030955\ttotal: 504ms\tremaining: 219ms\n",
            "92:\tlearn: 7006.3667399\ttotal: 509ms\tremaining: 214ms\n",
            "93:\tlearn: 6992.5107614\ttotal: 514ms\tremaining: 208ms\n",
            "94:\tlearn: 6958.3227460\ttotal: 519ms\tremaining: 202ms\n",
            "95:\tlearn: 6922.7561507\ttotal: 524ms\tremaining: 197ms\n",
            "96:\tlearn: 6904.3329679\ttotal: 529ms\tremaining: 191ms\n",
            "97:\tlearn: 6873.7013403\ttotal: 534ms\tremaining: 185ms\n",
            "98:\tlearn: 6840.4081771\ttotal: 540ms\tremaining: 180ms\n",
            "99:\tlearn: 6793.9740920\ttotal: 546ms\tremaining: 175ms\n",
            "100:\tlearn: 6779.1127743\ttotal: 550ms\tremaining: 169ms\n",
            "101:\tlearn: 6756.7057637\ttotal: 556ms\tremaining: 163ms\n",
            "102:\tlearn: 6738.1714222\ttotal: 560ms\tremaining: 158ms\n",
            "103:\tlearn: 6709.2305802\ttotal: 565ms\tremaining: 152ms\n",
            "104:\tlearn: 6691.4259305\ttotal: 570ms\tremaining: 147ms\n",
            "105:\tlearn: 6666.7417601\ttotal: 576ms\tremaining: 141ms\n",
            "106:\tlearn: 6646.6619031\ttotal: 581ms\tremaining: 136ms\n",
            "107:\tlearn: 6627.9065524\ttotal: 586ms\tremaining: 130ms\n",
            "108:\tlearn: 6614.3600873\ttotal: 591ms\tremaining: 125ms\n",
            "109:\tlearn: 6578.2930518\ttotal: 601ms\tremaining: 120ms\n",
            "110:\tlearn: 6554.3901252\ttotal: 610ms\tremaining: 115ms\n",
            "111:\tlearn: 6536.8245629\ttotal: 615ms\tremaining: 110ms\n",
            "112:\tlearn: 6525.3235438\ttotal: 620ms\tremaining: 104ms\n",
            "113:\tlearn: 6507.6738199\ttotal: 625ms\tremaining: 98.7ms\n",
            "114:\tlearn: 6493.7262797\ttotal: 630ms\tremaining: 93.1ms\n",
            "115:\tlearn: 6466.4754290\ttotal: 639ms\tremaining: 88.1ms\n",
            "116:\tlearn: 6449.5182623\ttotal: 644ms\tremaining: 82.5ms\n",
            "117:\tlearn: 6433.3807647\ttotal: 649ms\tremaining: 77ms\n",
            "118:\tlearn: 6407.4441531\ttotal: 654ms\tremaining: 71.4ms\n",
            "119:\tlearn: 6380.1141028\ttotal: 659ms\tremaining: 65.9ms\n",
            "120:\tlearn: 6361.4559359\ttotal: 664ms\tremaining: 60.4ms\n",
            "121:\tlearn: 6331.1776468\ttotal: 669ms\tremaining: 54.9ms\n",
            "122:\tlearn: 6314.2903357\ttotal: 675ms\tremaining: 49.4ms\n",
            "123:\tlearn: 6302.5943817\ttotal: 680ms\tremaining: 43.9ms\n",
            "124:\tlearn: 6287.2240545\ttotal: 685ms\tremaining: 38.3ms\n",
            "125:\tlearn: 6272.8663193\ttotal: 690ms\tremaining: 32.9ms\n",
            "126:\tlearn: 6263.0615755\ttotal: 696ms\tremaining: 27.4ms\n",
            "127:\tlearn: 6254.9717491\ttotal: 700ms\tremaining: 21.9ms\n",
            "128:\tlearn: 6235.1814977\ttotal: 706ms\tremaining: 16.4ms\n",
            "129:\tlearn: 6216.1174462\ttotal: 711ms\tremaining: 10.9ms\n",
            "130:\tlearn: 6205.7607625\ttotal: 716ms\tremaining: 5.47ms\n",
            "131:\tlearn: 6192.6391451\ttotal: 726ms\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004812 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1415\n",
            "[LightGBM] [Info] Number of data points in the train set: 23873, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 95099.778327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:33:19] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 64509.0218408\ttotal: 5.54ms\tremaining: 725ms\n",
            "1:\tlearn: 58697.7401398\ttotal: 11.4ms\tremaining: 743ms\n",
            "2:\tlearn: 53521.6071241\ttotal: 16.2ms\tremaining: 697ms\n",
            "3:\tlearn: 49620.1579442\ttotal: 21.1ms\tremaining: 674ms\n",
            "4:\tlearn: 45045.5275223\ttotal: 26.4ms\tremaining: 671ms\n",
            "5:\tlearn: 41419.6796135\ttotal: 31.5ms\tremaining: 662ms\n",
            "6:\tlearn: 38130.3023660\ttotal: 36.4ms\tremaining: 651ms\n",
            "7:\tlearn: 35246.2340753\ttotal: 41.7ms\tremaining: 646ms\n",
            "8:\tlearn: 32559.0956482\ttotal: 47ms\tremaining: 643ms\n",
            "9:\tlearn: 30401.7614094\ttotal: 52.4ms\tremaining: 639ms\n",
            "10:\tlearn: 28238.8662635\ttotal: 57.4ms\tremaining: 632ms\n",
            "11:\tlearn: 26506.6173839\ttotal: 62.9ms\tremaining: 629ms\n",
            "12:\tlearn: 25117.7800614\ttotal: 68ms\tremaining: 622ms\n",
            "13:\tlearn: 23721.1983058\ttotal: 73.3ms\tremaining: 617ms\n",
            "14:\tlearn: 22703.5365995\ttotal: 86.5ms\tremaining: 674ms\n",
            "15:\tlearn: 21434.5369217\ttotal: 91.6ms\tremaining: 664ms\n",
            "16:\tlearn: 20522.1551930\ttotal: 97.2ms\tremaining: 657ms\n",
            "17:\tlearn: 19821.4261747\ttotal: 102ms\tremaining: 646ms\n",
            "18:\tlearn: 18849.2677766\ttotal: 107ms\tremaining: 634ms\n",
            "19:\tlearn: 17963.1425935\ttotal: 112ms\tremaining: 628ms\n",
            "20:\tlearn: 17316.9149221\ttotal: 117ms\tremaining: 619ms\n",
            "21:\tlearn: 16891.0482145\ttotal: 122ms\tremaining: 610ms\n",
            "22:\tlearn: 16268.3408583\ttotal: 127ms\tremaining: 602ms\n",
            "23:\tlearn: 16028.0230921\ttotal: 132ms\tremaining: 594ms\n",
            "24:\tlearn: 15516.5981739\ttotal: 137ms\tremaining: 588ms\n",
            "25:\tlearn: 15061.8606943\ttotal: 142ms\tremaining: 579ms\n",
            "26:\tlearn: 14679.1020511\ttotal: 147ms\tremaining: 572ms\n",
            "27:\tlearn: 14385.0885273\ttotal: 152ms\tremaining: 565ms\n",
            "28:\tlearn: 14006.4284274\ttotal: 157ms\tremaining: 557ms\n",
            "29:\tlearn: 13692.1906049\ttotal: 162ms\tremaining: 549ms\n",
            "30:\tlearn: 13510.5902080\ttotal: 167ms\tremaining: 543ms\n",
            "31:\tlearn: 13086.2399617\ttotal: 172ms\tremaining: 538ms\n",
            "32:\tlearn: 12938.0293113\ttotal: 178ms\tremaining: 533ms\n",
            "33:\tlearn: 12690.2506014\ttotal: 184ms\tremaining: 531ms\n",
            "34:\tlearn: 12469.7617329\ttotal: 190ms\tremaining: 526ms\n",
            "35:\tlearn: 12156.6766949\ttotal: 195ms\tremaining: 519ms\n",
            "36:\tlearn: 12091.7785092\ttotal: 198ms\tremaining: 510ms\n",
            "37:\tlearn: 11922.8896610\ttotal: 206ms\tremaining: 509ms\n",
            "38:\tlearn: 11817.5885451\ttotal: 211ms\tremaining: 503ms\n",
            "39:\tlearn: 11541.7420834\ttotal: 216ms\tremaining: 496ms\n",
            "40:\tlearn: 11297.6553623\ttotal: 220ms\tremaining: 489ms\n",
            "41:\tlearn: 11223.4503867\ttotal: 225ms\tremaining: 482ms\n",
            "42:\tlearn: 11031.4937089\ttotal: 231ms\tremaining: 478ms\n",
            "43:\tlearn: 10949.0350262\ttotal: 236ms\tremaining: 471ms\n",
            "44:\tlearn: 10847.2614038\ttotal: 240ms\tremaining: 464ms\n",
            "45:\tlearn: 10802.6934782\ttotal: 245ms\tremaining: 458ms\n",
            "46:\tlearn: 10693.5570425\ttotal: 250ms\tremaining: 452ms\n",
            "47:\tlearn: 10529.7377864\ttotal: 254ms\tremaining: 445ms\n",
            "48:\tlearn: 10458.6987801\ttotal: 260ms\tremaining: 441ms\n",
            "49:\tlearn: 10379.8059397\ttotal: 265ms\tremaining: 434ms\n",
            "50:\tlearn: 10334.8989335\ttotal: 270ms\tremaining: 428ms\n",
            "51:\tlearn: 10198.2680834\ttotal: 275ms\tremaining: 423ms\n",
            "52:\tlearn: 10087.3961274\ttotal: 281ms\tremaining: 418ms\n",
            "53:\tlearn: 9888.6931033\ttotal: 285ms\tremaining: 412ms\n",
            "54:\tlearn: 9816.3843310\ttotal: 291ms\tremaining: 407ms\n",
            "55:\tlearn: 9696.2474845\ttotal: 298ms\tremaining: 404ms\n",
            "56:\tlearn: 9645.4937904\ttotal: 313ms\tremaining: 411ms\n",
            "57:\tlearn: 9606.2593473\ttotal: 326ms\tremaining: 416ms\n",
            "58:\tlearn: 9578.8192109\ttotal: 331ms\tremaining: 410ms\n",
            "59:\tlearn: 9480.1747395\ttotal: 336ms\tremaining: 403ms\n",
            "60:\tlearn: 9391.9017050\ttotal: 341ms\tremaining: 397ms\n",
            "61:\tlearn: 9339.4445902\ttotal: 345ms\tremaining: 390ms\n",
            "62:\tlearn: 9287.2450712\ttotal: 350ms\tremaining: 384ms\n",
            "63:\tlearn: 9242.2559460\ttotal: 355ms\tremaining: 378ms\n",
            "64:\tlearn: 9166.9428620\ttotal: 361ms\tremaining: 372ms\n",
            "65:\tlearn: 9078.8424217\ttotal: 365ms\tremaining: 365ms\n",
            "66:\tlearn: 9052.1535294\ttotal: 371ms\tremaining: 360ms\n",
            "67:\tlearn: 8970.8605195\ttotal: 376ms\tremaining: 354ms\n",
            "68:\tlearn: 8935.6751981\ttotal: 380ms\tremaining: 347ms\n",
            "69:\tlearn: 8848.3430861\ttotal: 385ms\tremaining: 341ms\n",
            "70:\tlearn: 8828.4702326\ttotal: 391ms\tremaining: 336ms\n",
            "71:\tlearn: 8790.3997600\ttotal: 399ms\tremaining: 333ms\n",
            "72:\tlearn: 8725.5207875\ttotal: 405ms\tremaining: 327ms\n",
            "73:\tlearn: 8644.5736382\ttotal: 410ms\tremaining: 321ms\n",
            "74:\tlearn: 8613.8402153\ttotal: 415ms\tremaining: 315ms\n",
            "75:\tlearn: 8542.3120579\ttotal: 420ms\tremaining: 309ms\n",
            "76:\tlearn: 8462.4002077\ttotal: 425ms\tremaining: 304ms\n",
            "77:\tlearn: 8411.5881671\ttotal: 430ms\tremaining: 298ms\n",
            "78:\tlearn: 8396.5694930\ttotal: 435ms\tremaining: 292ms\n",
            "79:\tlearn: 8377.5225600\ttotal: 440ms\tremaining: 286ms\n",
            "80:\tlearn: 8310.3249657\ttotal: 445ms\tremaining: 280ms\n",
            "81:\tlearn: 8293.2250920\ttotal: 449ms\tremaining: 274ms\n",
            "82:\tlearn: 8240.6689123\ttotal: 454ms\tremaining: 268ms\n",
            "83:\tlearn: 8193.0679672\ttotal: 459ms\tremaining: 262ms\n",
            "84:\tlearn: 8136.4159197\ttotal: 464ms\tremaining: 257ms\n",
            "85:\tlearn: 8093.8149178\ttotal: 469ms\tremaining: 251ms\n",
            "86:\tlearn: 8068.5391944\ttotal: 475ms\tremaining: 245ms\n",
            "87:\tlearn: 8011.8745525\ttotal: 479ms\tremaining: 240ms\n",
            "88:\tlearn: 7964.3454551\ttotal: 486ms\tremaining: 235ms\n",
            "89:\tlearn: 7944.2055941\ttotal: 493ms\tremaining: 230ms\n",
            "90:\tlearn: 7926.0883505\ttotal: 498ms\tremaining: 224ms\n",
            "91:\tlearn: 7902.9216574\ttotal: 503ms\tremaining: 219ms\n",
            "92:\tlearn: 7885.4308292\ttotal: 507ms\tremaining: 213ms\n",
            "93:\tlearn: 7838.6182363\ttotal: 515ms\tremaining: 208ms\n",
            "94:\tlearn: 7807.1361478\ttotal: 519ms\tremaining: 202ms\n",
            "95:\tlearn: 7790.2585902\ttotal: 524ms\tremaining: 197ms\n",
            "96:\tlearn: 7746.4647584\ttotal: 529ms\tremaining: 191ms\n",
            "97:\tlearn: 7701.9971105\ttotal: 535ms\tremaining: 185ms\n",
            "98:\tlearn: 7658.6570344\ttotal: 540ms\tremaining: 180ms\n",
            "99:\tlearn: 7629.6299348\ttotal: 545ms\tremaining: 175ms\n",
            "100:\tlearn: 7593.0590949\ttotal: 551ms\tremaining: 169ms\n",
            "101:\tlearn: 7566.0931165\ttotal: 557ms\tremaining: 164ms\n",
            "102:\tlearn: 7552.1475081\ttotal: 563ms\tremaining: 158ms\n",
            "103:\tlearn: 7522.3365100\ttotal: 568ms\tremaining: 153ms\n",
            "104:\tlearn: 7498.2791091\ttotal: 573ms\tremaining: 147ms\n",
            "105:\tlearn: 7468.7567162\ttotal: 578ms\tremaining: 142ms\n",
            "106:\tlearn: 7445.1788164\ttotal: 583ms\tremaining: 136ms\n",
            "107:\tlearn: 7425.5742563\ttotal: 590ms\tremaining: 131ms\n",
            "108:\tlearn: 7403.0925691\ttotal: 599ms\tremaining: 126ms\n",
            "109:\tlearn: 7378.6708087\ttotal: 604ms\tremaining: 121ms\n",
            "110:\tlearn: 7351.6825427\ttotal: 609ms\tremaining: 115ms\n",
            "111:\tlearn: 7327.4826375\ttotal: 614ms\tremaining: 110ms\n",
            "112:\tlearn: 7320.6300553\ttotal: 619ms\tremaining: 104ms\n",
            "113:\tlearn: 7297.2368705\ttotal: 624ms\tremaining: 98.6ms\n",
            "114:\tlearn: 7275.9359132\ttotal: 631ms\tremaining: 93.3ms\n",
            "115:\tlearn: 7250.8288566\ttotal: 636ms\tremaining: 87.7ms\n",
            "116:\tlearn: 7232.9412342\ttotal: 641ms\tremaining: 82.2ms\n",
            "117:\tlearn: 7211.0702868\ttotal: 646ms\tremaining: 76.7ms\n",
            "118:\tlearn: 7198.7348126\ttotal: 651ms\tremaining: 71.1ms\n",
            "119:\tlearn: 7181.9959087\ttotal: 656ms\tremaining: 65.6ms\n",
            "120:\tlearn: 7170.3881976\ttotal: 662ms\tremaining: 60.2ms\n",
            "121:\tlearn: 7149.3919178\ttotal: 667ms\tremaining: 54.7ms\n",
            "122:\tlearn: 7137.5857207\ttotal: 672ms\tremaining: 49.2ms\n",
            "123:\tlearn: 7120.6603235\ttotal: 677ms\tremaining: 43.7ms\n",
            "124:\tlearn: 7102.8951534\ttotal: 682ms\tremaining: 38.2ms\n",
            "125:\tlearn: 7083.8651421\ttotal: 687ms\tremaining: 32.7ms\n",
            "126:\tlearn: 7075.0926245\ttotal: 692ms\tremaining: 27.2ms\n",
            "127:\tlearn: 7058.3726656\ttotal: 697ms\tremaining: 21.8ms\n",
            "128:\tlearn: 7043.9375426\ttotal: 702ms\tremaining: 16.3ms\n",
            "129:\tlearn: 7028.8988628\ttotal: 708ms\tremaining: 10.9ms\n",
            "130:\tlearn: 7008.4307438\ttotal: 713ms\tremaining: 5.44ms\n",
            "131:\tlearn: 6989.9569747\ttotal: 719ms\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004942 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1392\n",
            "[LightGBM] [Info] Number of data points in the train set: 23840, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94430.404908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:33:20] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 63803.5479563\ttotal: 5.81ms\tremaining: 761ms\n",
            "1:\tlearn: 57464.7060720\ttotal: 11.7ms\tremaining: 763ms\n",
            "2:\tlearn: 52516.1176004\ttotal: 17ms\tremaining: 733ms\n",
            "3:\tlearn: 47723.0386095\ttotal: 22ms\tremaining: 705ms\n",
            "4:\tlearn: 43611.5135949\ttotal: 27.4ms\tremaining: 695ms\n",
            "5:\tlearn: 40286.3292197\ttotal: 32.5ms\tremaining: 683ms\n",
            "6:\tlearn: 37080.9929452\ttotal: 37.6ms\tremaining: 672ms\n",
            "7:\tlearn: 34211.3893485\ttotal: 42.9ms\tremaining: 665ms\n",
            "8:\tlearn: 31848.0242643\ttotal: 48.5ms\tremaining: 663ms\n",
            "9:\tlearn: 29970.4904562\ttotal: 53.7ms\tremaining: 655ms\n",
            "10:\tlearn: 28226.5242228\ttotal: 60.1ms\tremaining: 662ms\n",
            "11:\tlearn: 26702.2420489\ttotal: 65.3ms\tremaining: 653ms\n",
            "12:\tlearn: 25414.6878245\ttotal: 70.5ms\tremaining: 645ms\n",
            "13:\tlearn: 23955.0145436\ttotal: 76.2ms\tremaining: 642ms\n",
            "14:\tlearn: 23031.0403785\ttotal: 87.1ms\tremaining: 679ms\n",
            "15:\tlearn: 22076.9780589\ttotal: 91.9ms\tremaining: 666ms\n",
            "16:\tlearn: 21021.6951642\ttotal: 97.1ms\tremaining: 657ms\n",
            "17:\tlearn: 20411.8181563\ttotal: 102ms\tremaining: 646ms\n",
            "18:\tlearn: 19833.8421969\ttotal: 108ms\tremaining: 640ms\n",
            "19:\tlearn: 19275.6094993\ttotal: 113ms\tremaining: 633ms\n",
            "20:\tlearn: 18711.7402551\ttotal: 119ms\tremaining: 627ms\n",
            "21:\tlearn: 18168.9065728\ttotal: 124ms\tremaining: 620ms\n",
            "22:\tlearn: 17620.1664607\ttotal: 130ms\tremaining: 614ms\n",
            "23:\tlearn: 17324.4022702\ttotal: 135ms\tremaining: 608ms\n",
            "24:\tlearn: 16703.1890772\ttotal: 140ms\tremaining: 600ms\n",
            "25:\tlearn: 16326.2135973\ttotal: 145ms\tremaining: 591ms\n",
            "26:\tlearn: 15642.6108649\ttotal: 150ms\tremaining: 584ms\n",
            "27:\tlearn: 15288.9310252\ttotal: 155ms\tremaining: 577ms\n",
            "28:\tlearn: 14945.1005929\ttotal: 160ms\tremaining: 569ms\n",
            "29:\tlearn: 14544.0911538\ttotal: 165ms\tremaining: 561ms\n",
            "30:\tlearn: 14145.5814607\ttotal: 170ms\tremaining: 554ms\n",
            "31:\tlearn: 13861.2305076\ttotal: 175ms\tremaining: 547ms\n",
            "32:\tlearn: 13318.9358699\ttotal: 180ms\tremaining: 540ms\n",
            "33:\tlearn: 13075.3713654\ttotal: 187ms\tremaining: 538ms\n",
            "34:\tlearn: 12753.3237927\ttotal: 192ms\tremaining: 531ms\n",
            "35:\tlearn: 12327.7259699\ttotal: 197ms\tremaining: 525ms\n",
            "36:\tlearn: 12216.0268106\ttotal: 207ms\tremaining: 532ms\n",
            "37:\tlearn: 12104.1440538\ttotal: 212ms\tremaining: 525ms\n",
            "38:\tlearn: 11929.7714808\ttotal: 218ms\tremaining: 520ms\n",
            "39:\tlearn: 11563.9033461\ttotal: 223ms\tremaining: 513ms\n",
            "40:\tlearn: 11473.7182685\ttotal: 228ms\tremaining: 507ms\n",
            "41:\tlearn: 11370.8383200\ttotal: 234ms\tremaining: 502ms\n",
            "42:\tlearn: 11211.9240765\ttotal: 240ms\tremaining: 497ms\n",
            "43:\tlearn: 11041.4864513\ttotal: 245ms\tremaining: 491ms\n",
            "44:\tlearn: 10776.9032933\ttotal: 250ms\tremaining: 484ms\n",
            "45:\tlearn: 10683.7273760\ttotal: 255ms\tremaining: 477ms\n",
            "46:\tlearn: 10502.3612764\ttotal: 260ms\tremaining: 470ms\n",
            "47:\tlearn: 10397.7394276\ttotal: 265ms\tremaining: 463ms\n",
            "48:\tlearn: 10143.0648501\ttotal: 270ms\tremaining: 457ms\n",
            "49:\tlearn: 9979.6380779\ttotal: 274ms\tremaining: 450ms\n",
            "50:\tlearn: 9931.7201994\ttotal: 279ms\tremaining: 444ms\n",
            "51:\tlearn: 9860.6781554\ttotal: 284ms\tremaining: 437ms\n",
            "52:\tlearn: 9763.6697055\ttotal: 290ms\tremaining: 432ms\n",
            "53:\tlearn: 9624.7514057\ttotal: 295ms\tremaining: 425ms\n",
            "54:\tlearn: 9595.7824254\ttotal: 300ms\tremaining: 419ms\n",
            "55:\tlearn: 9468.5591312\ttotal: 310ms\tremaining: 420ms\n",
            "56:\tlearn: 9444.5302434\ttotal: 315ms\tremaining: 414ms\n",
            "57:\tlearn: 9289.9859894\ttotal: 321ms\tremaining: 409ms\n",
            "58:\tlearn: 9257.3106159\ttotal: 327ms\tremaining: 405ms\n",
            "59:\tlearn: 9224.3528243\ttotal: 332ms\tremaining: 398ms\n",
            "60:\tlearn: 9076.4620848\ttotal: 336ms\tremaining: 391ms\n",
            "61:\tlearn: 9046.5312897\ttotal: 341ms\tremaining: 385ms\n",
            "62:\tlearn: 8996.6620100\ttotal: 346ms\tremaining: 378ms\n",
            "63:\tlearn: 8903.7036401\ttotal: 350ms\tremaining: 372ms\n",
            "64:\tlearn: 8837.2508634\ttotal: 356ms\tremaining: 367ms\n",
            "65:\tlearn: 8726.4560396\ttotal: 360ms\tremaining: 360ms\n",
            "66:\tlearn: 8702.1724956\ttotal: 365ms\tremaining: 354ms\n",
            "67:\tlearn: 8634.3509040\ttotal: 370ms\tremaining: 349ms\n",
            "68:\tlearn: 8554.5535476\ttotal: 376ms\tremaining: 343ms\n",
            "69:\tlearn: 8494.5359439\ttotal: 381ms\tremaining: 338ms\n",
            "70:\tlearn: 8469.5042693\ttotal: 386ms\tremaining: 332ms\n",
            "71:\tlearn: 8437.8140036\ttotal: 397ms\tremaining: 331ms\n",
            "72:\tlearn: 8407.1552467\ttotal: 402ms\tremaining: 325ms\n",
            "73:\tlearn: 8333.0215993\ttotal: 406ms\tremaining: 319ms\n",
            "74:\tlearn: 8287.3987749\ttotal: 412ms\tremaining: 313ms\n",
            "75:\tlearn: 8269.3852658\ttotal: 417ms\tremaining: 307ms\n",
            "76:\tlearn: 8234.3134827\ttotal: 423ms\tremaining: 302ms\n",
            "77:\tlearn: 8206.8954382\ttotal: 428ms\tremaining: 296ms\n",
            "78:\tlearn: 8168.4654575\ttotal: 433ms\tremaining: 290ms\n",
            "79:\tlearn: 8112.9468832\ttotal: 437ms\tremaining: 284ms\n",
            "80:\tlearn: 8059.1804390\ttotal: 442ms\tremaining: 278ms\n",
            "81:\tlearn: 8024.4564491\ttotal: 448ms\tremaining: 273ms\n",
            "82:\tlearn: 7980.3340621\ttotal: 453ms\tremaining: 267ms\n",
            "83:\tlearn: 7959.1452975\ttotal: 460ms\tremaining: 263ms\n",
            "84:\tlearn: 7939.8367865\ttotal: 465ms\tremaining: 257ms\n",
            "85:\tlearn: 7917.2546431\ttotal: 470ms\tremaining: 252ms\n",
            "86:\tlearn: 7900.5771823\ttotal: 476ms\tremaining: 246ms\n",
            "87:\tlearn: 7877.2259477\ttotal: 481ms\tremaining: 240ms\n",
            "88:\tlearn: 7825.9141272\ttotal: 485ms\tremaining: 234ms\n",
            "89:\tlearn: 7781.0242816\ttotal: 490ms\tremaining: 229ms\n",
            "90:\tlearn: 7745.8135120\ttotal: 496ms\tremaining: 223ms\n",
            "91:\tlearn: 7712.6015527\ttotal: 501ms\tremaining: 218ms\n",
            "92:\tlearn: 7686.5322027\ttotal: 506ms\tremaining: 212ms\n",
            "93:\tlearn: 7670.0804053\ttotal: 511ms\tremaining: 207ms\n",
            "94:\tlearn: 7639.0870213\ttotal: 517ms\tremaining: 201ms\n",
            "95:\tlearn: 7585.4382780\ttotal: 522ms\tremaining: 196ms\n",
            "96:\tlearn: 7558.8691173\ttotal: 528ms\tremaining: 190ms\n",
            "97:\tlearn: 7525.5475163\ttotal: 537ms\tremaining: 186ms\n",
            "98:\tlearn: 7492.3521211\ttotal: 544ms\tremaining: 181ms\n",
            "99:\tlearn: 7463.2251244\ttotal: 549ms\tremaining: 176ms\n",
            "100:\tlearn: 7428.6892014\ttotal: 554ms\tremaining: 170ms\n",
            "101:\tlearn: 7416.8917673\ttotal: 559ms\tremaining: 164ms\n",
            "102:\tlearn: 7386.7133916\ttotal: 567ms\tremaining: 160ms\n",
            "103:\tlearn: 7359.2519921\ttotal: 572ms\tremaining: 154ms\n",
            "104:\tlearn: 7337.6191594\ttotal: 577ms\tremaining: 148ms\n",
            "105:\tlearn: 7312.5737820\ttotal: 583ms\tremaining: 143ms\n",
            "106:\tlearn: 7291.9380122\ttotal: 588ms\tremaining: 137ms\n",
            "107:\tlearn: 7277.8518270\ttotal: 597ms\tremaining: 133ms\n",
            "108:\tlearn: 7257.4620502\ttotal: 602ms\tremaining: 127ms\n",
            "109:\tlearn: 7241.7503037\ttotal: 608ms\tremaining: 122ms\n",
            "110:\tlearn: 7228.6051428\ttotal: 613ms\tremaining: 116ms\n",
            "111:\tlearn: 7216.7359807\ttotal: 618ms\tremaining: 110ms\n",
            "112:\tlearn: 7193.5746629\ttotal: 624ms\tremaining: 105ms\n",
            "113:\tlearn: 7176.9228963\ttotal: 629ms\tremaining: 99.3ms\n",
            "114:\tlearn: 7158.0378521\ttotal: 634ms\tremaining: 93.7ms\n",
            "115:\tlearn: 7144.1691604\ttotal: 639ms\tremaining: 88.1ms\n",
            "116:\tlearn: 7134.7847875\ttotal: 644ms\tremaining: 82.6ms\n",
            "117:\tlearn: 7112.7894958\ttotal: 650ms\tremaining: 77.1ms\n",
            "118:\tlearn: 7099.6179832\ttotal: 655ms\tremaining: 71.5ms\n",
            "119:\tlearn: 7086.7455616\ttotal: 663ms\tremaining: 66.3ms\n",
            "120:\tlearn: 7071.5908284\ttotal: 668ms\tremaining: 60.7ms\n",
            "121:\tlearn: 7056.7438928\ttotal: 673ms\tremaining: 55.2ms\n",
            "122:\tlearn: 7041.4213481\ttotal: 679ms\tremaining: 49.7ms\n",
            "123:\tlearn: 7026.1590384\ttotal: 684ms\tremaining: 44.1ms\n",
            "124:\tlearn: 7008.7317155\ttotal: 690ms\tremaining: 38.6ms\n",
            "125:\tlearn: 6995.9979081\ttotal: 695ms\tremaining: 33.1ms\n",
            "126:\tlearn: 6983.3333195\ttotal: 700ms\tremaining: 27.6ms\n",
            "127:\tlearn: 6973.0594458\ttotal: 705ms\tremaining: 22ms\n",
            "128:\tlearn: 6956.1509393\ttotal: 711ms\tremaining: 16.5ms\n",
            "129:\tlearn: 6940.2276181\ttotal: 716ms\tremaining: 11ms\n",
            "130:\tlearn: 6929.6042460\ttotal: 721ms\tremaining: 5.5ms\n",
            "131:\tlearn: 6920.7519881\ttotal: 726ms\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004843 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 23918, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 96483.595702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:33:22] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 63864.0885553\ttotal: 5.74ms\tremaining: 751ms\n",
            "1:\tlearn: 57894.8984297\ttotal: 13.3ms\tremaining: 865ms\n",
            "2:\tlearn: 52944.1340443\ttotal: 18.4ms\tremaining: 793ms\n",
            "3:\tlearn: 48161.8124817\ttotal: 23.1ms\tremaining: 740ms\n",
            "4:\tlearn: 43945.6029003\ttotal: 28ms\tremaining: 711ms\n",
            "5:\tlearn: 40358.0714762\ttotal: 33ms\tremaining: 692ms\n",
            "6:\tlearn: 36700.7539400\ttotal: 38.5ms\tremaining: 688ms\n",
            "7:\tlearn: 33569.7280422\ttotal: 43.9ms\tremaining: 680ms\n",
            "8:\tlearn: 31148.5820053\ttotal: 49.7ms\tremaining: 679ms\n",
            "9:\tlearn: 29129.9463339\ttotal: 54.7ms\tremaining: 667ms\n",
            "10:\tlearn: 27263.2069485\ttotal: 59.9ms\tremaining: 659ms\n",
            "11:\tlearn: 25405.1629722\ttotal: 66.3ms\tremaining: 663ms\n",
            "12:\tlearn: 24046.1292692\ttotal: 71.7ms\tremaining: 656ms\n",
            "13:\tlearn: 22716.6513126\ttotal: 76.6ms\tremaining: 645ms\n",
            "14:\tlearn: 21839.6346805\ttotal: 85.6ms\tremaining: 668ms\n",
            "15:\tlearn: 20649.4088436\ttotal: 91ms\tremaining: 660ms\n",
            "16:\tlearn: 19615.5236704\ttotal: 96.3ms\tremaining: 652ms\n",
            "17:\tlearn: 18925.3973360\ttotal: 102ms\tremaining: 643ms\n",
            "18:\tlearn: 18201.5360139\ttotal: 107ms\tremaining: 637ms\n",
            "19:\tlearn: 17547.1006580\ttotal: 113ms\tremaining: 631ms\n",
            "20:\tlearn: 17023.8266274\ttotal: 118ms\tremaining: 623ms\n",
            "21:\tlearn: 16356.9683112\ttotal: 123ms\tremaining: 614ms\n",
            "22:\tlearn: 15661.8836141\ttotal: 128ms\tremaining: 606ms\n",
            "23:\tlearn: 15110.3640968\ttotal: 133ms\tremaining: 599ms\n",
            "24:\tlearn: 14626.7759186\ttotal: 140ms\tremaining: 601ms\n",
            "25:\tlearn: 14314.7748612\ttotal: 146ms\tremaining: 594ms\n",
            "26:\tlearn: 13857.7852896\ttotal: 150ms\tremaining: 585ms\n",
            "27:\tlearn: 13437.1801950\ttotal: 155ms\tremaining: 577ms\n",
            "28:\tlearn: 13041.6273259\ttotal: 160ms\tremaining: 570ms\n",
            "29:\tlearn: 12690.0249266\ttotal: 165ms\tremaining: 561ms\n",
            "30:\tlearn: 12380.1658402\ttotal: 170ms\tremaining: 555ms\n",
            "31:\tlearn: 12083.9724227\ttotal: 176ms\tremaining: 550ms\n",
            "32:\tlearn: 11769.7482902\ttotal: 186ms\tremaining: 557ms\n",
            "33:\tlearn: 11490.2051695\ttotal: 191ms\tremaining: 550ms\n",
            "34:\tlearn: 11265.0321482\ttotal: 196ms\tremaining: 543ms\n",
            "35:\tlearn: 11127.0914837\ttotal: 205ms\tremaining: 547ms\n",
            "36:\tlearn: 10959.2971851\ttotal: 212ms\tremaining: 545ms\n",
            "37:\tlearn: 10838.8262167\ttotal: 217ms\tremaining: 537ms\n",
            "38:\tlearn: 10695.4485628\ttotal: 222ms\tremaining: 529ms\n",
            "39:\tlearn: 10496.8419300\ttotal: 227ms\tremaining: 522ms\n",
            "40:\tlearn: 10380.0699472\ttotal: 232ms\tremaining: 514ms\n",
            "41:\tlearn: 10251.7976624\ttotal: 242ms\tremaining: 519ms\n",
            "42:\tlearn: 10090.0045274\ttotal: 257ms\tremaining: 531ms\n",
            "43:\tlearn: 10026.7808742\ttotal: 263ms\tremaining: 527ms\n",
            "44:\tlearn: 9886.0509072\ttotal: 269ms\tremaining: 519ms\n",
            "45:\tlearn: 9765.6261967\ttotal: 274ms\tremaining: 512ms\n",
            "46:\tlearn: 9696.5638368\ttotal: 279ms\tremaining: 505ms\n",
            "47:\tlearn: 9643.2255447\ttotal: 284ms\tremaining: 497ms\n",
            "48:\tlearn: 9583.5516209\ttotal: 289ms\tremaining: 489ms\n",
            "49:\tlearn: 9508.8145624\ttotal: 294ms\tremaining: 482ms\n",
            "50:\tlearn: 9383.2744721\ttotal: 299ms\tremaining: 475ms\n",
            "51:\tlearn: 9332.5156806\ttotal: 304ms\tremaining: 467ms\n",
            "52:\tlearn: 9242.3796995\ttotal: 309ms\tremaining: 460ms\n",
            "53:\tlearn: 9138.7764385\ttotal: 314ms\tremaining: 453ms\n",
            "54:\tlearn: 9005.5814383\ttotal: 319ms\tremaining: 446ms\n",
            "55:\tlearn: 8957.6930013\ttotal: 323ms\tremaining: 439ms\n",
            "56:\tlearn: 8916.0287514\ttotal: 328ms\tremaining: 432ms\n",
            "57:\tlearn: 8839.4556818\ttotal: 334ms\tremaining: 426ms\n",
            "58:\tlearn: 8757.8505688\ttotal: 339ms\tremaining: 419ms\n",
            "59:\tlearn: 8729.1183198\ttotal: 344ms\tremaining: 413ms\n",
            "60:\tlearn: 8680.1581209\ttotal: 349ms\tremaining: 406ms\n",
            "61:\tlearn: 8612.2819982\ttotal: 354ms\tremaining: 400ms\n",
            "62:\tlearn: 8581.4919053\ttotal: 360ms\tremaining: 394ms\n",
            "63:\tlearn: 8541.4740821\ttotal: 365ms\tremaining: 388ms\n",
            "64:\tlearn: 8492.6839596\ttotal: 370ms\tremaining: 381ms\n",
            "65:\tlearn: 8473.2721830\ttotal: 375ms\tremaining: 375ms\n",
            "66:\tlearn: 8446.0302629\ttotal: 381ms\tremaining: 369ms\n",
            "67:\tlearn: 8404.7523987\ttotal: 386ms\tremaining: 363ms\n",
            "68:\tlearn: 8333.8681354\ttotal: 391ms\tremaining: 357ms\n",
            "69:\tlearn: 8303.0030894\ttotal: 398ms\tremaining: 352ms\n",
            "70:\tlearn: 8269.9035074\ttotal: 405ms\tremaining: 348ms\n",
            "71:\tlearn: 8215.1817410\ttotal: 410ms\tremaining: 342ms\n",
            "72:\tlearn: 8158.4721216\ttotal: 415ms\tremaining: 336ms\n",
            "73:\tlearn: 8133.2395816\ttotal: 420ms\tremaining: 330ms\n",
            "74:\tlearn: 8085.9158578\ttotal: 426ms\tremaining: 323ms\n",
            "75:\tlearn: 8057.7271969\ttotal: 431ms\tremaining: 317ms\n",
            "76:\tlearn: 8033.3007225\ttotal: 435ms\tremaining: 311ms\n",
            "77:\tlearn: 8017.7529652\ttotal: 445ms\tremaining: 308ms\n",
            "78:\tlearn: 7991.5934603\ttotal: 451ms\tremaining: 303ms\n",
            "79:\tlearn: 7956.1361314\ttotal: 456ms\tremaining: 296ms\n",
            "80:\tlearn: 7887.1369611\ttotal: 461ms\tremaining: 290ms\n",
            "81:\tlearn: 7871.1348450\ttotal: 466ms\tremaining: 284ms\n",
            "82:\tlearn: 7821.9646183\ttotal: 471ms\tremaining: 278ms\n",
            "83:\tlearn: 7793.7791572\ttotal: 476ms\tremaining: 272ms\n",
            "84:\tlearn: 7742.1666250\ttotal: 482ms\tremaining: 266ms\n",
            "85:\tlearn: 7713.8158327\ttotal: 487ms\tremaining: 260ms\n",
            "86:\tlearn: 7694.4736551\ttotal: 493ms\tremaining: 255ms\n",
            "87:\tlearn: 7670.7451072\ttotal: 498ms\tremaining: 249ms\n",
            "88:\tlearn: 7650.8295939\ttotal: 503ms\tremaining: 243ms\n",
            "89:\tlearn: 7616.4321906\ttotal: 509ms\tremaining: 237ms\n",
            "90:\tlearn: 7581.7237207\ttotal: 513ms\tremaining: 231ms\n",
            "91:\tlearn: 7564.5089955\ttotal: 519ms\tremaining: 225ms\n",
            "92:\tlearn: 7534.9171583\ttotal: 524ms\tremaining: 220ms\n",
            "93:\tlearn: 7515.1561985\ttotal: 530ms\tremaining: 214ms\n",
            "94:\tlearn: 7485.8252907\ttotal: 535ms\tremaining: 209ms\n",
            "95:\tlearn: 7447.1574944\ttotal: 541ms\tremaining: 203ms\n",
            "96:\tlearn: 7430.5974801\ttotal: 546ms\tremaining: 197ms\n",
            "97:\tlearn: 7418.3304803\ttotal: 551ms\tremaining: 191ms\n",
            "98:\tlearn: 7376.3024275\ttotal: 557ms\tremaining: 186ms\n",
            "99:\tlearn: 7345.6463694\ttotal: 563ms\tremaining: 180ms\n",
            "100:\tlearn: 7314.4291858\ttotal: 567ms\tremaining: 174ms\n",
            "101:\tlearn: 7285.1799512\ttotal: 573ms\tremaining: 169ms\n",
            "102:\tlearn: 7254.5101485\ttotal: 578ms\tremaining: 163ms\n",
            "103:\tlearn: 7226.6990345\ttotal: 583ms\tremaining: 157ms\n",
            "104:\tlearn: 7212.8445652\ttotal: 588ms\tremaining: 151ms\n",
            "105:\tlearn: 7184.9584645\ttotal: 600ms\tremaining: 147ms\n",
            "106:\tlearn: 7155.2763064\ttotal: 606ms\tremaining: 142ms\n",
            "107:\tlearn: 7144.8532770\ttotal: 612ms\tremaining: 136ms\n",
            "108:\tlearn: 7109.2154785\ttotal: 618ms\tremaining: 130ms\n",
            "109:\tlearn: 7095.7254445\ttotal: 624ms\tremaining: 125ms\n",
            "110:\tlearn: 7073.4471561\ttotal: 630ms\tremaining: 119ms\n",
            "111:\tlearn: 7060.6983702\ttotal: 635ms\tremaining: 113ms\n",
            "112:\tlearn: 7040.1590507\ttotal: 640ms\tremaining: 108ms\n",
            "113:\tlearn: 7021.7139094\ttotal: 645ms\tremaining: 102ms\n",
            "114:\tlearn: 7008.4147445\ttotal: 650ms\tremaining: 96.1ms\n",
            "115:\tlearn: 6985.0015070\ttotal: 656ms\tremaining: 90.5ms\n",
            "116:\tlearn: 6968.3085880\ttotal: 662ms\tremaining: 84.8ms\n",
            "117:\tlearn: 6955.3840021\ttotal: 667ms\tremaining: 79.2ms\n",
            "118:\tlearn: 6934.1027497\ttotal: 674ms\tremaining: 73.7ms\n",
            "119:\tlearn: 6910.3055695\ttotal: 680ms\tremaining: 68ms\n",
            "120:\tlearn: 6882.9196770\ttotal: 685ms\tremaining: 62.3ms\n",
            "121:\tlearn: 6867.6445485\ttotal: 690ms\tremaining: 56.6ms\n",
            "122:\tlearn: 6858.0079681\ttotal: 695ms\tremaining: 50.9ms\n",
            "123:\tlearn: 6837.0539056\ttotal: 700ms\tremaining: 45.2ms\n",
            "124:\tlearn: 6821.3064535\ttotal: 706ms\tremaining: 39.5ms\n",
            "125:\tlearn: 6808.2224206\ttotal: 711ms\tremaining: 33.9ms\n",
            "126:\tlearn: 6790.3204410\ttotal: 716ms\tremaining: 28.2ms\n",
            "127:\tlearn: 6770.2208081\ttotal: 722ms\tremaining: 22.6ms\n",
            "128:\tlearn: 6749.8464898\ttotal: 730ms\tremaining: 17ms\n",
            "129:\tlearn: 6733.4506352\ttotal: 736ms\tremaining: 11.3ms\n",
            "130:\tlearn: 6717.8837030\ttotal: 745ms\tremaining: 5.69ms\n",
            "131:\tlearn: 6709.5229216\ttotal: 751ms\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004971 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 24442, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 95189.703134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [02:33:23] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 41265.0749224\ttotal: 5.71ms\tremaining: 747ms\n",
            "1:\tlearn: 37015.7790312\ttotal: 11.8ms\tremaining: 766ms\n",
            "2:\tlearn: 33262.1523149\ttotal: 17.8ms\tremaining: 766ms\n",
            "3:\tlearn: 29912.8411285\ttotal: 23.1ms\tremaining: 740ms\n",
            "4:\tlearn: 27364.6323943\ttotal: 28.4ms\tremaining: 721ms\n",
            "5:\tlearn: 24768.5763854\ttotal: 33.9ms\tremaining: 713ms\n",
            "6:\tlearn: 22401.4146110\ttotal: 39.3ms\tremaining: 702ms\n",
            "7:\tlearn: 20278.0796355\ttotal: 44.6ms\tremaining: 691ms\n",
            "8:\tlearn: 18418.9015162\ttotal: 49.9ms\tremaining: 682ms\n",
            "9:\tlearn: 16789.2393744\ttotal: 55.5ms\tremaining: 677ms\n",
            "10:\tlearn: 15518.4040039\ttotal: 60.7ms\tremaining: 668ms\n",
            "11:\tlearn: 14245.8694330\ttotal: 66.3ms\tremaining: 663ms\n",
            "12:\tlearn: 13156.1040865\ttotal: 71.7ms\tremaining: 656ms\n",
            "13:\tlearn: 12161.8636785\ttotal: 77.1ms\tremaining: 650ms\n",
            "14:\tlearn: 11331.9881316\ttotal: 85.8ms\tremaining: 669ms\n",
            "15:\tlearn: 10601.3077324\ttotal: 91.9ms\tremaining: 666ms\n",
            "16:\tlearn: 9980.2555350\ttotal: 97.3ms\tremaining: 658ms\n",
            "17:\tlearn: 9454.6020352\ttotal: 102ms\tremaining: 648ms\n",
            "18:\tlearn: 8999.1906864\ttotal: 108ms\tremaining: 644ms\n",
            "19:\tlearn: 8604.8829455\ttotal: 114ms\tremaining: 636ms\n",
            "20:\tlearn: 8281.5848431\ttotal: 119ms\tremaining: 628ms\n",
            "21:\tlearn: 8038.8038381\ttotal: 124ms\tremaining: 619ms\n",
            "22:\tlearn: 7800.6964111\ttotal: 129ms\tremaining: 613ms\n",
            "23:\tlearn: 7605.2463175\ttotal: 137ms\tremaining: 618ms\n",
            "24:\tlearn: 7435.5688000\ttotal: 143ms\tremaining: 610ms\n",
            "25:\tlearn: 7283.8732088\ttotal: 148ms\tremaining: 603ms\n",
            "26:\tlearn: 7171.6021815\ttotal: 153ms\tremaining: 596ms\n",
            "27:\tlearn: 7076.7040387\ttotal: 159ms\tremaining: 589ms\n",
            "28:\tlearn: 6992.0875745\ttotal: 164ms\tremaining: 582ms\n",
            "29:\tlearn: 6926.5388184\ttotal: 169ms\tremaining: 576ms\n",
            "30:\tlearn: 6900.2143771\ttotal: 178ms\tremaining: 581ms\n",
            "31:\tlearn: 6844.4518453\ttotal: 184ms\tremaining: 574ms\n",
            "32:\tlearn: 6780.5544576\ttotal: 189ms\tremaining: 566ms\n",
            "33:\tlearn: 6741.3828163\ttotal: 193ms\tremaining: 558ms\n",
            "34:\tlearn: 6705.6099149\ttotal: 203ms\tremaining: 563ms\n",
            "35:\tlearn: 6674.2177099\ttotal: 212ms\tremaining: 565ms\n",
            "36:\tlearn: 6653.8895930\ttotal: 217ms\tremaining: 557ms\n",
            "37:\tlearn: 6613.1150111\ttotal: 224ms\tremaining: 554ms\n",
            "38:\tlearn: 6578.8913792\ttotal: 229ms\tremaining: 546ms\n",
            "39:\tlearn: 6545.1641427\ttotal: 235ms\tremaining: 540ms\n",
            "40:\tlearn: 6517.9381749\ttotal: 240ms\tremaining: 533ms\n",
            "41:\tlearn: 6494.6182487\ttotal: 245ms\tremaining: 526ms\n",
            "42:\tlearn: 6472.2756295\ttotal: 251ms\tremaining: 519ms\n",
            "43:\tlearn: 6459.5674213\ttotal: 257ms\tremaining: 515ms\n",
            "44:\tlearn: 6427.8122490\ttotal: 265ms\tremaining: 512ms\n",
            "45:\tlearn: 6411.6239446\ttotal: 270ms\tremaining: 506ms\n",
            "46:\tlearn: 6397.6327558\ttotal: 276ms\tremaining: 498ms\n",
            "47:\tlearn: 6382.8123544\ttotal: 281ms\tremaining: 492ms\n",
            "48:\tlearn: 6365.6803706\ttotal: 286ms\tremaining: 485ms\n",
            "49:\tlearn: 6348.1205767\ttotal: 291ms\tremaining: 478ms\n",
            "50:\tlearn: 6331.5277589\ttotal: 298ms\tremaining: 474ms\n",
            "51:\tlearn: 6319.6574374\ttotal: 307ms\tremaining: 472ms\n",
            "52:\tlearn: 6305.2688469\ttotal: 312ms\tremaining: 465ms\n",
            "53:\tlearn: 6284.8325865\ttotal: 318ms\tremaining: 459ms\n",
            "54:\tlearn: 6269.4308175\ttotal: 323ms\tremaining: 452ms\n",
            "55:\tlearn: 6256.1907373\ttotal: 328ms\tremaining: 445ms\n",
            "56:\tlearn: 6228.8098331\ttotal: 334ms\tremaining: 440ms\n",
            "57:\tlearn: 6217.0716030\ttotal: 340ms\tremaining: 433ms\n",
            "58:\tlearn: 6190.3156653\ttotal: 345ms\tremaining: 427ms\n",
            "59:\tlearn: 6177.8572829\ttotal: 350ms\tremaining: 420ms\n",
            "60:\tlearn: 6163.8351152\ttotal: 355ms\tremaining: 413ms\n",
            "61:\tlearn: 6151.6288407\ttotal: 360ms\tremaining: 407ms\n",
            "62:\tlearn: 6130.6805721\ttotal: 367ms\tremaining: 402ms\n",
            "63:\tlearn: 6109.2260223\ttotal: 372ms\tremaining: 395ms\n",
            "64:\tlearn: 6094.6501378\ttotal: 377ms\tremaining: 389ms\n",
            "65:\tlearn: 6079.3969691\ttotal: 382ms\tremaining: 382ms\n",
            "66:\tlearn: 6066.6163777\ttotal: 387ms\tremaining: 376ms\n",
            "67:\tlearn: 6054.5341980\ttotal: 392ms\tremaining: 369ms\n",
            "68:\tlearn: 6031.9871694\ttotal: 405ms\tremaining: 370ms\n",
            "69:\tlearn: 6016.0355020\ttotal: 411ms\tremaining: 364ms\n",
            "70:\tlearn: 5999.3109972\ttotal: 416ms\tremaining: 357ms\n",
            "71:\tlearn: 5984.0843313\ttotal: 421ms\tremaining: 351ms\n",
            "72:\tlearn: 5964.6285974\ttotal: 426ms\tremaining: 345ms\n",
            "73:\tlearn: 5952.1399184\ttotal: 432ms\tremaining: 338ms\n",
            "74:\tlearn: 5938.2550234\ttotal: 437ms\tremaining: 332ms\n",
            "75:\tlearn: 5930.6320221\ttotal: 443ms\tremaining: 326ms\n",
            "76:\tlearn: 5921.8289782\ttotal: 448ms\tremaining: 320ms\n",
            "77:\tlearn: 5914.6808169\ttotal: 453ms\tremaining: 314ms\n",
            "78:\tlearn: 5905.6074137\ttotal: 459ms\tremaining: 308ms\n",
            "79:\tlearn: 5893.7736066\ttotal: 463ms\tremaining: 301ms\n",
            "80:\tlearn: 5882.3759332\ttotal: 469ms\tremaining: 295ms\n",
            "81:\tlearn: 5876.3391643\ttotal: 474ms\tremaining: 289ms\n",
            "82:\tlearn: 5866.4769518\ttotal: 479ms\tremaining: 283ms\n",
            "83:\tlearn: 5851.0849856\ttotal: 494ms\tremaining: 282ms\n",
            "84:\tlearn: 5840.8923210\ttotal: 500ms\tremaining: 277ms\n",
            "85:\tlearn: 5827.7897815\ttotal: 506ms\tremaining: 271ms\n",
            "86:\tlearn: 5813.1071646\ttotal: 511ms\tremaining: 265ms\n",
            "87:\tlearn: 5802.2205595\ttotal: 517ms\tremaining: 258ms\n",
            "88:\tlearn: 5798.3922107\ttotal: 522ms\tremaining: 252ms\n",
            "89:\tlearn: 5790.9127377\ttotal: 529ms\tremaining: 247ms\n",
            "90:\tlearn: 5781.6284905\ttotal: 537ms\tremaining: 242ms\n",
            "91:\tlearn: 5776.6516140\ttotal: 542ms\tremaining: 236ms\n",
            "92:\tlearn: 5756.4860733\ttotal: 548ms\tremaining: 230ms\n",
            "93:\tlearn: 5746.8692911\ttotal: 553ms\tremaining: 223ms\n",
            "94:\tlearn: 5737.3328347\ttotal: 558ms\tremaining: 217ms\n",
            "95:\tlearn: 5726.9096975\ttotal: 563ms\tremaining: 211ms\n",
            "96:\tlearn: 5717.8144125\ttotal: 568ms\tremaining: 205ms\n",
            "97:\tlearn: 5707.3971162\ttotal: 574ms\tremaining: 199ms\n",
            "98:\tlearn: 5701.2247013\ttotal: 579ms\tremaining: 193ms\n",
            "99:\tlearn: 5691.0982115\ttotal: 584ms\tremaining: 187ms\n",
            "100:\tlearn: 5687.2445186\ttotal: 589ms\tremaining: 181ms\n",
            "101:\tlearn: 5682.3804710\ttotal: 595ms\tremaining: 175ms\n",
            "102:\tlearn: 5673.0894865\ttotal: 606ms\tremaining: 171ms\n",
            "103:\tlearn: 5667.1062105\ttotal: 612ms\tremaining: 165ms\n",
            "104:\tlearn: 5656.9078234\ttotal: 617ms\tremaining: 159ms\n",
            "105:\tlearn: 5651.9377134\ttotal: 623ms\tremaining: 153ms\n",
            "106:\tlearn: 5638.2120910\ttotal: 628ms\tremaining: 147ms\n",
            "107:\tlearn: 5630.1873455\ttotal: 634ms\tremaining: 141ms\n",
            "108:\tlearn: 5624.0363992\ttotal: 639ms\tremaining: 135ms\n",
            "109:\tlearn: 5611.3264091\ttotal: 645ms\tremaining: 129ms\n",
            "110:\tlearn: 5604.3523126\ttotal: 658ms\tremaining: 124ms\n",
            "111:\tlearn: 5592.1988774\ttotal: 672ms\tremaining: 120ms\n",
            "112:\tlearn: 5580.4455575\ttotal: 678ms\tremaining: 114ms\n",
            "113:\tlearn: 5574.4445406\ttotal: 683ms\tremaining: 108ms\n",
            "114:\tlearn: 5568.5324748\ttotal: 688ms\tremaining: 102ms\n",
            "115:\tlearn: 5557.7359754\ttotal: 694ms\tremaining: 95.7ms\n",
            "116:\tlearn: 5552.5485417\ttotal: 700ms\tremaining: 89.7ms\n",
            "117:\tlearn: 5542.0142724\ttotal: 707ms\tremaining: 83.8ms\n",
            "118:\tlearn: 5536.6306715\ttotal: 712ms\tremaining: 77.8ms\n",
            "119:\tlearn: 5528.1142154\ttotal: 717ms\tremaining: 71.7ms\n",
            "120:\tlearn: 5521.2343665\ttotal: 723ms\tremaining: 65.7ms\n",
            "121:\tlearn: 5515.5355409\ttotal: 728ms\tremaining: 59.6ms\n",
            "122:\tlearn: 5509.4378372\ttotal: 733ms\tremaining: 53.6ms\n",
            "123:\tlearn: 5505.4699551\ttotal: 737ms\tremaining: 47.6ms\n",
            "124:\tlearn: 5499.2915023\ttotal: 743ms\tremaining: 41.6ms\n",
            "125:\tlearn: 5490.1470940\ttotal: 748ms\tremaining: 35.6ms\n",
            "126:\tlearn: 5482.2388665\ttotal: 753ms\tremaining: 29.6ms\n",
            "127:\tlearn: 5476.0507651\ttotal: 758ms\tremaining: 23.7ms\n",
            "128:\tlearn: 5465.8257874\ttotal: 763ms\tremaining: 17.7ms\n",
            "129:\tlearn: 5461.2375053\ttotal: 768ms\tremaining: 11.8ms\n",
            "130:\tlearn: 5455.0611516\ttotal: 774ms\tremaining: 5.91ms\n",
            "131:\tlearn: 5445.9442713\ttotal: 779ms\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003336 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1369\n",
            "[LightGBM] [Info] Number of data points in the train set: 23927, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 91081.871902\n"
          ]
        }
      ],
      "source": [
        "folds = 5\n",
        "kf = GroupKFold(folds)\n",
        "out1 = pd.Series()\n",
        "out2 = pd.Series()\n",
        "out3 = pd.Series()\n",
        "for train_idx, test_idx in kf.split(model_data, groups=model_data['circuit']):\n",
        "  train = model_data.iloc[train_idx]\n",
        "  test = model_data.iloc[test_idx]\n",
        "  # test[target] = 0\n",
        "  xtrain = xgb.DMatrix(train.loc[:, feats], train[target])\n",
        "  xtest = xgb.DMatrix(test.loc[:, feats], test[target])\n",
        "  ltrain = lgb.Dataset(train.loc[:, feats], train[target])\n",
        "  ltest = lgb.Dataset(test.loc[:, feats], test[target])\n",
        "\n",
        "  model = xgb.train(xgbp, xtrain)\n",
        "  _s1 = pd.Series(model.predict(xtest), index=test.index)\n",
        "  out1 = pd.concat([out1, _s1])\n",
        "\n",
        "  model = cb.CatBoostRegressor(**cbp)\n",
        "  model.fit(train.loc[:, feats], train[target])\n",
        "  _s2 = pd.Series(model.predict(test.loc[:, feats]), index=test.index)\n",
        "  out2 = pd.concat([out2, _s2])\n",
        "\n",
        "  model = lgb.train(lgbp, ltrain)\n",
        "  _s = pd.Series(model.predict(test.loc[:, feats]), index=test.index)\n",
        "  _s3 = pd.Series(model.predict(test.loc[:, feats]), index=test.index)\n",
        "  out3 = pd.concat([out3, _s3])\n",
        "\n",
        "\n",
        "model_data[f'{target}_xgb'] = out1\n",
        "model_data[f'{target}_cb'] = out2\n",
        "model_data[f'{target}_lgb'] = out3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "CzbR2XgOQblW",
        "outputId": "aae425b0-e4d2-44c3-b4f0-afe5079fd044"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '24px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[111078.3688788478, 59803.41629886789, 55128.5507721433]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "[\n",
        "    mean_squared_error(model_data[target], model_data[f\"{target}_xgb\"])**0.5,\n",
        "    mean_squared_error(model_data[target], model_data[f\"{target}_cb\"])**0.5,\n",
        "    mean_squared_error(model_data[target], model_data[f\"{target}_lgb\"])**0.5,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9S19XgtSRgK"
      },
      "source": [
        "[65631.05732838159, 64410.03829021576, 70924.77368354828]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYS5Ji70YDhq"
      },
      "outputs": [],
      "source": [
        "hp = {\n",
        "    'epochs':10,\n",
        "    'hidden':[200,200],\n",
        "}\n",
        "htrain = h2o.H2OFrame(model_data)\n",
        "htrain[target] = htrain[target].asfactor()\n",
        "nn = H2ODeepLearningEstimator(**hp)\n",
        "nn.train(x=[f'{target}_xgb',f'{target}_cb',f'{target}_lgb'], y=target, training_frame=htrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "KjwvnuCbNxVH",
        "outputId": "cf45be1e-f842-4a68-a76e-3a94cf63187e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '24px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPRegressor()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "nn = MLPRegressor()\n",
        "nn.fit(model_data.loc[:, [f'{target}_xgb',f'{target}_cb',f'{target}_lgb']], model_data[target])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FDu65HW8N4h5",
        "outputId": "cd1c51b2-a55a-47b9-b99b-93c076de2663"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '24px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-6b6acca6aa20>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[target] = 0\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [04:01:05] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_round\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "<ipython-input-22-6b6acca6aa20>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[f'{target}_xgb'] = pd.Series(model.predict(xtest), index=test.index)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 57326.2815049\ttotal: 28.6ms\tremaining: 3.75s\n",
            "1:\tlearn: 51546.3309292\ttotal: 38.7ms\tremaining: 2.51s\n",
            "2:\tlearn: 46473.8167704\ttotal: 46.1ms\tremaining: 1.98s\n",
            "3:\tlearn: 42434.2286398\ttotal: 53.9ms\tremaining: 1.72s\n",
            "4:\tlearn: 38567.7822739\ttotal: 61.1ms\tremaining: 1.55s\n",
            "5:\tlearn: 35566.6109478\ttotal: 68.8ms\tremaining: 1.45s\n",
            "6:\tlearn: 32609.6391151\ttotal: 88.9ms\tremaining: 1.59s\n",
            "7:\tlearn: 30025.8336357\ttotal: 116ms\tremaining: 1.8s\n",
            "8:\tlearn: 27781.1489239\ttotal: 136ms\tremaining: 1.86s\n",
            "9:\tlearn: 25859.3047272\ttotal: 160ms\tremaining: 1.95s\n",
            "10:\tlearn: 24183.4454462\ttotal: 178ms\tremaining: 1.96s\n",
            "11:\tlearn: 22867.6211177\ttotal: 193ms\tremaining: 1.93s\n",
            "12:\tlearn: 21759.5287445\ttotal: 210ms\tremaining: 1.93s\n",
            "13:\tlearn: 20682.1929885\ttotal: 231ms\tremaining: 1.95s\n",
            "14:\tlearn: 19776.4950315\ttotal: 238ms\tremaining: 1.86s\n",
            "15:\tlearn: 18983.6647741\ttotal: 248ms\tremaining: 1.79s\n",
            "16:\tlearn: 18396.2805319\ttotal: 271ms\tremaining: 1.83s\n",
            "17:\tlearn: 17643.0232930\ttotal: 280ms\tremaining: 1.78s\n",
            "18:\tlearn: 17151.5131343\ttotal: 288ms\tremaining: 1.71s\n",
            "19:\tlearn: 16642.0880687\ttotal: 300ms\tremaining: 1.68s\n",
            "20:\tlearn: 16262.0270831\ttotal: 319ms\tremaining: 1.69s\n",
            "21:\tlearn: 15768.2112225\ttotal: 326ms\tremaining: 1.63s\n",
            "22:\tlearn: 15332.4067295\ttotal: 341ms\tremaining: 1.61s\n",
            "23:\tlearn: 14792.7776356\ttotal: 348ms\tremaining: 1.56s\n",
            "24:\tlearn: 14452.6143011\ttotal: 356ms\tremaining: 1.52s\n",
            "25:\tlearn: 14090.0293698\ttotal: 363ms\tremaining: 1.48s\n",
            "26:\tlearn: 13671.4312917\ttotal: 370ms\tremaining: 1.44s\n",
            "27:\tlearn: 13219.5579444\ttotal: 376ms\tremaining: 1.4s\n",
            "28:\tlearn: 12979.1084201\ttotal: 392ms\tremaining: 1.39s\n",
            "29:\tlearn: 12591.6772018\ttotal: 408ms\tremaining: 1.39s\n",
            "30:\tlearn: 12350.1843671\ttotal: 428ms\tremaining: 1.39s\n",
            "31:\tlearn: 12182.2651702\ttotal: 443ms\tremaining: 1.38s\n",
            "32:\tlearn: 11967.9157741\ttotal: 474ms\tremaining: 1.42s\n",
            "33:\tlearn: 11750.9119721\ttotal: 497ms\tremaining: 1.43s\n",
            "34:\tlearn: 11442.6776393\ttotal: 506ms\tremaining: 1.4s\n",
            "35:\tlearn: 11324.2475617\ttotal: 514ms\tremaining: 1.37s\n",
            "36:\tlearn: 11231.7682094\ttotal: 533ms\tremaining: 1.37s\n",
            "37:\tlearn: 11013.9702307\ttotal: 568ms\tremaining: 1.4s\n",
            "38:\tlearn: 10870.9149181\ttotal: 599ms\tremaining: 1.43s\n",
            "39:\tlearn: 10607.7202821\ttotal: 623ms\tremaining: 1.43s\n",
            "40:\tlearn: 10387.7497228\ttotal: 651ms\tremaining: 1.45s\n",
            "41:\tlearn: 10303.4102841\ttotal: 668ms\tremaining: 1.43s\n",
            "42:\tlearn: 10213.8551654\ttotal: 701ms\tremaining: 1.45s\n",
            "43:\tlearn: 10107.7298416\ttotal: 733ms\tremaining: 1.47s\n",
            "44:\tlearn: 9972.1416698\ttotal: 767ms\tremaining: 1.48s\n",
            "45:\tlearn: 9909.8683333\ttotal: 782ms\tremaining: 1.46s\n",
            "46:\tlearn: 9727.3646140\ttotal: 801ms\tremaining: 1.45s\n",
            "47:\tlearn: 9632.7558913\ttotal: 816ms\tremaining: 1.43s\n",
            "48:\tlearn: 9452.0278271\ttotal: 839ms\tremaining: 1.42s\n",
            "49:\tlearn: 9417.5918590\ttotal: 875ms\tremaining: 1.43s\n",
            "50:\tlearn: 9382.4719384\ttotal: 904ms\tremaining: 1.44s\n",
            "51:\tlearn: 9308.9297822\ttotal: 945ms\tremaining: 1.45s\n",
            "52:\tlearn: 9200.7429553\ttotal: 977ms\tremaining: 1.46s\n",
            "53:\tlearn: 9116.5730715\ttotal: 995ms\tremaining: 1.44s\n",
            "54:\tlearn: 8970.6517020\ttotal: 1.01s\tremaining: 1.41s\n",
            "55:\tlearn: 8849.0979350\ttotal: 1.02s\tremaining: 1.39s\n",
            "56:\tlearn: 8831.9185183\ttotal: 1.04s\tremaining: 1.37s\n",
            "57:\tlearn: 8751.8625613\ttotal: 1.06s\tremaining: 1.35s\n",
            "58:\tlearn: 8641.0977031\ttotal: 1.07s\tremaining: 1.33s\n",
            "59:\tlearn: 8559.8527228\ttotal: 1.09s\tremaining: 1.31s\n",
            "60:\tlearn: 8496.4336043\ttotal: 1.11s\tremaining: 1.29s\n",
            "61:\tlearn: 8438.0600618\ttotal: 1.13s\tremaining: 1.27s\n",
            "62:\tlearn: 8428.1382659\ttotal: 1.14s\tremaining: 1.25s\n",
            "63:\tlearn: 8408.5747065\ttotal: 1.16s\tremaining: 1.23s\n",
            "64:\tlearn: 8352.2655545\ttotal: 1.19s\tremaining: 1.23s\n",
            "65:\tlearn: 8330.3599203\ttotal: 1.21s\tremaining: 1.21s\n",
            "66:\tlearn: 8264.3729910\ttotal: 1.24s\tremaining: 1.2s\n",
            "67:\tlearn: 8202.7753716\ttotal: 1.26s\tremaining: 1.18s\n",
            "68:\tlearn: 8179.2008653\ttotal: 1.27s\tremaining: 1.16s\n",
            "69:\tlearn: 8139.4462843\ttotal: 1.29s\tremaining: 1.14s\n",
            "70:\tlearn: 8130.9114291\ttotal: 1.3s\tremaining: 1.12s\n",
            "71:\tlearn: 8088.4373653\ttotal: 1.34s\tremaining: 1.11s\n",
            "72:\tlearn: 8025.8301250\ttotal: 1.36s\tremaining: 1.1s\n",
            "73:\tlearn: 7965.0595480\ttotal: 1.38s\tremaining: 1.08s\n",
            "74:\tlearn: 7910.5181469\ttotal: 1.41s\tremaining: 1.07s\n",
            "75:\tlearn: 7865.7153598\ttotal: 1.44s\tremaining: 1.06s\n",
            "76:\tlearn: 7807.3280811\ttotal: 1.46s\tremaining: 1.04s\n",
            "77:\tlearn: 7791.1672331\ttotal: 1.49s\tremaining: 1.03s\n",
            "78:\tlearn: 7758.2456422\ttotal: 1.5s\tremaining: 1s\n",
            "79:\tlearn: 7715.9859995\ttotal: 1.52s\tremaining: 988ms\n",
            "80:\tlearn: 7656.3003382\ttotal: 1.54s\tremaining: 969ms\n",
            "81:\tlearn: 7615.9135622\ttotal: 1.56s\tremaining: 954ms\n",
            "82:\tlearn: 7588.6897667\ttotal: 1.58s\tremaining: 932ms\n",
            "83:\tlearn: 7551.1496323\ttotal: 1.6s\tremaining: 916ms\n",
            "84:\tlearn: 7521.1955927\ttotal: 1.62s\tremaining: 896ms\n",
            "85:\tlearn: 7497.0321310\ttotal: 1.63s\tremaining: 874ms\n",
            "86:\tlearn: 7481.1913652\ttotal: 1.65s\tremaining: 853ms\n",
            "87:\tlearn: 7448.6435302\ttotal: 1.67s\tremaining: 833ms\n",
            "88:\tlearn: 7446.0423545\ttotal: 1.67s\tremaining: 808ms\n",
            "89:\tlearn: 7418.9506130\ttotal: 1.69s\tremaining: 788ms\n",
            "90:\tlearn: 7387.2809210\ttotal: 1.71s\tremaining: 770ms\n",
            "91:\tlearn: 7344.9753621\ttotal: 1.73s\tremaining: 751ms\n",
            "92:\tlearn: 7315.1926988\ttotal: 1.74s\tremaining: 731ms\n",
            "93:\tlearn: 7287.8901637\ttotal: 1.76s\tremaining: 710ms\n",
            "94:\tlearn: 7260.9832813\ttotal: 1.77s\tremaining: 691ms\n",
            "95:\tlearn: 7249.4306598\ttotal: 1.81s\tremaining: 681ms\n",
            "96:\tlearn: 7224.1357998\ttotal: 1.83s\tremaining: 661ms\n",
            "97:\tlearn: 7204.3262535\ttotal: 1.87s\tremaining: 648ms\n",
            "98:\tlearn: 7191.3204229\ttotal: 1.88s\tremaining: 627ms\n",
            "99:\tlearn: 7162.5229311\ttotal: 1.91s\tremaining: 610ms\n",
            "100:\tlearn: 7137.8548155\ttotal: 1.92s\tremaining: 591ms\n",
            "101:\tlearn: 7110.7998442\ttotal: 1.93s\tremaining: 569ms\n",
            "102:\tlearn: 7086.8689555\ttotal: 1.94s\tremaining: 547ms\n",
            "103:\tlearn: 7071.7016944\ttotal: 1.96s\tremaining: 527ms\n",
            "104:\tlearn: 7045.1616669\ttotal: 1.97s\tremaining: 507ms\n",
            "105:\tlearn: 7027.6299785\ttotal: 1.99s\tremaining: 488ms\n",
            "106:\tlearn: 7010.4442167\ttotal: 2s\tremaining: 466ms\n",
            "107:\tlearn: 6988.3944296\ttotal: 2s\tremaining: 445ms\n",
            "108:\tlearn: 6975.1634002\ttotal: 2.02s\tremaining: 426ms\n",
            "109:\tlearn: 6966.6466767\ttotal: 2.02s\tremaining: 405ms\n",
            "110:\tlearn: 6956.2632911\ttotal: 2.03s\tremaining: 385ms\n",
            "111:\tlearn: 6930.4470659\ttotal: 2.04s\tremaining: 365ms\n",
            "112:\tlearn: 6912.9622423\ttotal: 2.05s\tremaining: 345ms\n",
            "113:\tlearn: 6896.7213335\ttotal: 2.06s\tremaining: 325ms\n",
            "114:\tlearn: 6888.0128137\ttotal: 2.08s\tremaining: 307ms\n",
            "115:\tlearn: 6868.7908420\ttotal: 2.1s\tremaining: 289ms\n",
            "116:\tlearn: 6854.7595844\ttotal: 2.11s\tremaining: 270ms\n",
            "117:\tlearn: 6848.7389449\ttotal: 2.12s\tremaining: 252ms\n",
            "118:\tlearn: 6826.0337797\ttotal: 2.13s\tremaining: 233ms\n",
            "119:\tlearn: 6816.2326649\ttotal: 2.14s\tremaining: 214ms\n",
            "120:\tlearn: 6799.9312653\ttotal: 2.15s\tremaining: 196ms\n",
            "121:\tlearn: 6786.6066770\ttotal: 2.17s\tremaining: 178ms\n",
            "122:\tlearn: 6764.6641077\ttotal: 2.18s\tremaining: 159ms\n",
            "123:\tlearn: 6753.8990862\ttotal: 2.19s\tremaining: 141ms\n",
            "124:\tlearn: 6741.7343496\ttotal: 2.2s\tremaining: 123ms\n",
            "125:\tlearn: 6728.6622683\ttotal: 2.21s\tremaining: 105ms\n",
            "126:\tlearn: 6709.4323340\ttotal: 2.22s\tremaining: 87.4ms\n",
            "127:\tlearn: 6701.0218763\ttotal: 2.23s\tremaining: 69.7ms\n",
            "128:\tlearn: 6684.5217364\ttotal: 2.24s\tremaining: 52ms\n",
            "129:\tlearn: 6678.7882953\ttotal: 2.24s\tremaining: 34.5ms\n",
            "130:\tlearn: 6661.2498032\ttotal: 2.25s\tremaining: 17.2ms\n",
            "131:\tlearn: 6644.9185082\ttotal: 2.26s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-6b6acca6aa20>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[f'{target}_cb'] = pd.Series(model.predict(test.loc[:, feats]), index=test.index)\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009064 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1486\n",
            "[LightGBM] [Info] Number of data points in the train set: 30000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 94459.793133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-6b6acca6aa20>:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[f'{target}_lgb'] = pd.Series(model.predict(test.loc[:, feats]), index=test.index)\n",
            "<ipython-input-22-6b6acca6aa20>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[target] = pd.Series(nn.predict(test.loc[:, [f'{target}_xgb',f'{target}_cb',f'{target}_lgb']]), index=test.index)\n"
          ]
        }
      ],
      "source": [
        "train = data.loc[data['test']==0]\n",
        "test = data.loc[data['test']==1]\n",
        "test[target] = 0\n",
        "xtrain = xgb.DMatrix(train.loc[:, feats], train[target])\n",
        "xtest = xgb.DMatrix(test.loc[:, feats], test[target])\n",
        "ltrain = lgb.Dataset(train.loc[:, feats], train[target])\n",
        "ltest = lgb.Dataset(test.loc[:, feats], test[target])\n",
        "\n",
        "model = xgb.train(xgbp, xtrain)\n",
        "test[f'{target}_xgb'] = pd.Series(model.predict(xtest), index=test.index)\n",
        "\n",
        "\n",
        "model = cb.CatBoostRegressor(**cbp)\n",
        "model.fit(train.loc[:, feats], train[target])\n",
        "test[f'{target}_cb'] = pd.Series(model.predict(test.loc[:, feats]), index=test.index)\n",
        "\n",
        "model = lgb.train(lgbp, ltrain)\n",
        "test[f'{target}_lgb'] = pd.Series(model.predict(test.loc[:, feats]), index=test.index)\n",
        "\n",
        "test[target] = pd.Series(nn.predict(test.loc[:, [f'{target}_xgb',f'{target}_cb',f'{target}_lgb']]), index=test.index)\n",
        "test.loc[:, ['id', target]].to_csv('newlul.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmINw1-WNJLA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8rXvU1jNJPL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1DxEM2Bqb3ADy6wu2bGOm4uufDC98bFos",
      "authorship_tag": "ABX9TyP8hHL29pftOtls++Q/rMLJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}